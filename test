import numpy as np
import pandas as pd
from scipy.stats import kurtosis

# Example dictionary with tokens as keys.
# 'varun' has multiple tiles (rows) and multiple features (columns).
token_shap = {
    'varun': np.array([
        [1, 2, 3],
        [3, 4, 5],
        [1, 2, 3]
    ]),
    # A token with a single tile (row). Not enough data for reliable kurtosis.
    'single_token': np.array([[1, 2, 3]])
}

results = []
for token, shap_vals in token_shap.items():
    token_result = {'token': token}
    
    if shap_vals.ndim == 2:
        if shap_vals.shape[0] > 1:
            # Compute column-wise kurtosis along axis 0.
            col_kurt = kurtosis(shap_vals, axis=0)
        else:
            # With only one row, there's insufficient data to compute kurtosis reliably.
            # Here, we assign NaN for each column.
            col_kurt = np.full(shap_vals.shape[1], np.nan)
    else:
        # For a 1D array, compute the overall kurtosis.
        col_kurt = np.array([kurtosis(shap_vals)])
    
    # Store the column-wise kurtosis values in the result dictionary.
    for i, k_val in enumerate(col_kurt):
        token_result[f'col_{i}'] = k_val
    results.append(token_result)

# Create a DataFrame to display the results.
df = pd.DataFrame(results)
print(df)
