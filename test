import os
import pandas as pd
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH

def build_template_with_df(
    df: pd.DataFrame,
    model: str,
    impact: str,
    scope: str = "",
    save_dir: str = "base"
) -> str:
    """
    Create a Validation Report DOCX directly from a DataFrame.
    Each row contributes:
      - Question i: <IMVP Question>
      - Team response (modelling team + MRMG answers)
    """
    os.makedirs(save_dir, exist_ok=True)
    fname = f"{model}_{impact}{('_' + scope) if scope else ''}.docx"
    out_path = os.path.join(save_dir, fname)

    doc = Document()

    # Title
    p = doc.add_paragraph()
    run = p.add_run("Validation Report (Auto Generated)")
    run.font.size = Pt(16)
    run.bold = True
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph()

    # Metadata line
    doc.add_paragraph(f"Model: {model} | Impact: {impact}{(' | Scope: ' + scope) if scope else ''}")
    doc.add_paragraph()

    # Loop rows from DataFrame
    for i, row in df.iterrows():
        # Question
        q = doc.add_paragraph()
        rq = q.add_run(f"Question {i+1}: {row['IMVP Question']}")
        rq.bold = True
        rq.font.size = Pt(12)

        # Modelling team response
        if "modelling_team_answer" in row and pd.notna(row["modelling_team_answer"]):
            tr1 = doc.add_paragraph()
            rr1 = tr1.add_run(f"Modelling Team Response: {row['modelling_team_answer']}")
            rr1.italic = True

        # MRMG team response
        if "mrmg_answer" in row and pd.notna(row["mrmg_answer"]):
            tr2 = doc.add_paragraph()
            rr2 = tr2.add_run(f"MRMG Response: {row['mrmg_answer']}")
            rr2.italic = True

        doc.add_paragraph()  # spacer between questions

    doc.save(out_path)
    return out_path        throttle_every=throttle_every,
        throttle_sleep=throttle_sleep
    )

    payloads: List[Dict] = []
    chunk_image_map: List[int] = []

    # Prepare payloads for each image
    for idx, chunk in enumerate(preprocessed_chunks):
        images = chunk.get("image_context") or []
        if not isinstance(images, list):
            logger.warning(f"chunk[{idx}].image_context is not a list; skipping.")
            continue

        for base64_image in images:
            # Normalize/clean the base64 if needed
            clean_b64 = normalize_base64_image(base64_image)
            payloads.append({
                "input_nodes": {"base_64_encoded_image": clean_b64}
            })
            chunk_image_map.append(idx)

    if not payloads:
        logger.info("No images found in any chunk; returning chunks unchanged.")
        return preprocessed_chunks

    # Invoke LLM with throttling
    results = llm_batcher.invoke_batch(payloads, batch_size=batch_size)

    # Map LLM results back to their chunks
    chunk_output_map: Dict[int, List[str]] = defaultdict(list)
    for chunk_idx, output in zip(chunk_image_map, results):
        chunk_output_map[chunk_idx].append(output)

    # Replace image_context with only LLM outputs
    for idx, outputs in chunk_output_map.items():
        preprocessed_chunks[idx]["image_context"] = outputs

    return preprocessed_chunks
