## Presentation: Evaluating Data Drift Using KS and MMD Metrics

### Objective
The goal of this analysis is to evaluate data drift in a three-class BERT-based text classification model. The classes include:
- Lifestyle
- Travel
- Member Service

We inject noisy words into the data and assess the drift using KS (Kolmogorov-Smirnov) and MMD (Maximum Mean Discrepancy) metrics. The results are compared between the normal data and perturbed datasets to quantify the extent of drift.

---

### Methodology

#### 1. Data Preparation
We split the original test set into:
- **Reference Dataset:** A subset of the original test set.
- **H0 Dataset:** A subset of the test set that should not be rejected under the null hypothesis.
- **Imbalanced Datasets:** Artificially imbalanced subsets.

#### Code for Data Splitting:
```python
import numpy as np

def random_sample(X: np.ndarray, y: np.ndarray, proba_zero: float, n: int):
    idx_0 = np.where(y == 0)[0]
    idx_1 = np.where(y == 1)[0]
    n_0, n_1 = int(n * proba_zero), int(n * (1 - proba_zero))
    idx_0_out = np.random.choice(idx_0, n_0, replace=False)
    idx_1_out = np.random.choice(idx_1, n_1, replace=False)
    X_out = np.concatenate([X[idx_0_out], X[idx_1_out]])
    y_out = np.concatenate([y[idx_0_out], y[idx_1_out]])
    return X_out.tolist(), y_out.tolist()
```

#### 2. Noisy Word Injection
We injected selected noisy words such as “fantastic,” “good,” “bad,” and “horrible” into the dataset at varying perturbation levels (1% and 5% of tokens per instance). 

Code snippet for word injection:
```python
def inject_word(token: int, X: np.ndarray, perc_chg: float):
    seq_len = X.shape[1]
    n_chg = int(perc_chg * 0.01 * seq_len)
    X_cp = X.copy()
    for i in range(X.shape[0]):
        idx = np.random.choice(np.arange(seq_len), n_chg, replace=False)
        X_cp[i, idx] = token
    return X_cp.tolist()
```

---

### Results

#### 1. Drift Evaluation on H0 Dataset
We verified that the H0 dataset does not exhibit drift. This serves as a baseline.

**Results:**
- Drift: No
- P-value: [Example Values]

#### 2. Drift Evaluation on Imbalanced Datasets
We created imbalanced datasets with different proportions of the classes and evaluated drift.

**Results:**
- 10% Negative Sentiment:
  - Drift: Yes
  - P-value: [Example Values]
- 90% Negative Sentiment:
  - Drift: Yes
  - P-value: [Example Values]

#### 3. Drift Evaluation on Noisy Word Injection
We injected noisy words at different perturbation levels (1% and 5%) and checked for drift.

**Results:**
- **Word: Fantastic**
  - 1% Perturbed: Drift = No, P-value = [0.88, 0.91, ...]
  - 5% Perturbed: Drift = Yes, P-value = [1.29e-02, 1.52e-11, ...]

- **Word: Good**
  - 1% Perturbed: Drift = Yes, P-value = [0.34, 0.98, ...]
  - 5% Perturbed: Drift = Yes, P-value = [6.13e-16, 2.40e-04, ...]

- **Word: Bad**
  - 1% Perturbed: Drift = No, P-value = [0.88, 0.95, ...]
  - 5% Perturbed: Drift = Yes, P-value = [7.04e-08, 3.69e-01, ...]

---

### Visualizations
#### 1. KS and MMD Metrics Across Datasets
- [Insert KS metric visualization comparing normal and perturbed datasets]
- [Insert MMD visualization for imbalanced datasets]

#### 2. Class Distribution
- Reference vs. Imbalanced Datasets:
  - Bar plot showing class proportions.

#### 3. Perturbation Impact
- Word-level drift plots at 1% and 5% perturbation levels.

---

### Key Takeaways
1. Drift was successfully detected in imbalanced and perturbed datasets.
2. Higher perturbation levels led to significant drift, as evidenced by lower p-values.
3. KS and MMD metrics provide reliable measures to quantify data drift.
4. Drift detection ensures the robustness of the BERT-based classification model.

---

### Next Steps
1. Implement additional mitigation strategies to handle data drift in production.
2. Regularly monitor KS and MMD metrics to ensure model performance.
3. Explore other metrics or methods to detect drift at a finer granularity.

---

**Thank you!**

