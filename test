import asyncio
from agent_framework import ChatAgent
from agent_framework import MCPStreamableHTTPTool
from agent_framework import BaseChatClient
from agent_framework import ChatMessage, Role, TextContent, ChatResponse
from safechain.lcel import model
from langchain_core.prompts import ChatPromptTemplate
from typing import Sequence, Any


class MyChatClient(BaseChatClient):
    async def _inner_get_response(
        self,
        messages: Sequence[ChatMessage],
        *,
        tools=None,
        **kwargs: Any,
    ) -> ChatResponse:

        prompt = ChatPromptTemplate.from_messages(
            [(m.role.value, m.contents[0].text) for m in messages]
        ).format_prompt()

        llm = model("3")
        result = llm.invoke(prompt)

        return ChatResponse(
            messages=ChatMessage(
                role=Role.ASSISTANT,
                contents=[TextContent(text=result.content)],
            )
        )


# --------------------------------------------------
# MCP TOOL WRAPPER
# --------------------------------------------------
travel_mcp = MCPStreamableHTTPTool(
    name="travel_mcp",
    url="http://localhost:8006",
)

# --------------------------------------------------
# Agent
# --------------------------------------------------
class GreetingAgent(ChatAgent):
    def __init__(self):
        super().__init__(
            name="GreetingAgent",
            chat_client=MyChatClient(),
            instructions="Use MCP tools for time and weather when helpful.",
            tools=[travel_mcp],  # ðŸ‘ˆ MCP SERVER
        )


async def main():
    agent = GreetingAgent()
    response = await agent.run("Hi, how is the weather?")
    print(response.text)


if __name__ == "__main__":
    asyncio.run(main())
