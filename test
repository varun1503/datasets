# =========================================================
# JUPYTER NOTEBOOK ‚Äì OFFICIAL-STYLE CHATCLIENT IMPLEMENTATION
# =========================================================

import asyncio
from typing import List, Any, MutableMapping, Sequence, Callable

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompt_values import ChatPromptValue

from agent_framework import ChatAgent
from agent_framework.clients import BaseChatClient
from agent_framework.messages import ChatMessage, Role, TextContent
from agent_framework.types import ToolProtocol


# =========================================================
# SAFE TEXT EXTRACTION (VERSION AGNOSTIC)
# =========================================================
def extract_text_from_message(m: ChatMessage) -> str:
    if hasattr(m, "content") and m.content:
        return extract_text_from_content(m.content)
    if hasattr(m, "contents") and m.contents:
        return extract_text_from_content(m.contents[0])
    return ""

def extract_text_from_content(c) -> str:
    if hasattr(c, "value"):
        return c.value
    if hasattr(c, "text"):
        return c.text
    if hasattr(c, "data"):
        return c.data
    return ""


# =========================================================
# ORG STANDARD MODEL FACTORY
# =========================================================
def model(version: str):
    return MyCustomLLM(version)


# =========================================================
# YOUR CUSTOM LLM (ChatPromptValue ONLY)
# =========================================================
class MyCustomLLM:
    def __init__(self, version: str):
        self.version = version

    def invoke(self, prompt_value: ChatPromptValue) -> ChatMessage:
        print(f"\nüîµ LLM model({self.version}) INVOKED\n")
        print(prompt_value.to_string())

        return ChatMessage(
            role=Role.ASSISTANT,
            contents=[
                TextContent(text="Hello üëã This response came from model('3')")
            ],
        )


# =========================================================
# OFFICIAL-STYLE CUSTOM CHAT CLIENT
# =========================================================
class MyChatClient(BaseChatClient):
    """
    Matches agent-framework's official ChatClient design.
    """

    async def get_response(
        self,
        messages: Sequence[ChatMessage],
        *,
        tools: Sequence[ToolProtocol] | None = None,
        tool_choice: Callable[..., Any] | None = None,
        chat_options: MutableMapping[str, Any] | None = None,
        **kwargs: Any,
    ) -> ChatMessage:
        """
        This method is REQUIRED by ChatAgent.
        """

        # 1Ô∏è‚É£ Convert messages ‚Üí ChatPromptTemplate
        prompt_template = ChatPromptTemplate.from_messages(
            [(m.role, extract_text_from_message(m)) for m in messages]
        )

        # 2Ô∏è‚É£ Convert ‚Üí ChatPromptValue
        prompt_value = prompt_template.format_prompt()

        # 3Ô∏è‚É£ ORG STANDARD LLM CALL
        llm = model("3")
        response_message = llm.invoke(prompt_value)

        return response_message


# =========================================================
# GREETING AGENT
# =========================================================
class GreetingAgent(ChatAgent):
    def __init__(self):
        super().__init__(
            name="GreetingAgent",
            chat_client=MyChatClient(),  # ‚úÖ OFFICIAL STYLE
            instructions="You are a friendly greeting assistant.",
        )


# =========================================================
# RUN
# =========================================================
async def main():
    agent = GreetingAgent()
    response = await agent.run("Hi")

    print("\nüü¢ FINAL RESPONSE TEXT:\n")
    print(extract_text_from_message(response.messages[0]))

await main()
