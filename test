import re
import json
import unicodedata
from typing import List, Dict, Tuple
from docx import Document
from collections import OrderedDict

# ---------- helpers ----------
def norm(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()


def read_docx_lines(path: str) -> List[str]:
    doc = Document(path)
    lines: List[str] = []
    for p in doc.paragraphs:
        t = norm(p.text)
        if t:
            lines.append(t)
    for tbl in doc.tables:
        for row in tbl.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    t = norm(p.text)
                    if t:
                        lines.append(t)
    return lines


# ---------- patterns ----------
REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)
RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)  # tolerant
BRACKETS_RX = re.compile(r"<\s*([^>]+?)\s*>")
Q_KEY_RX = re.compile(r"^\s*Q\d+\s*:\s*", re.IGNORECASE)
RESP_HDR_RX = re.compile(r"Modeling Team[â€™']?s Response", re.IGNORECASE)


def extract_meta_from_rfr_header(line: str) -> Tuple[str, str, str]:
    q_key = ""
    section = ""
    imvp = ""
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    # Q may also end with '?', so detect by prefix not by '?'
    for part in parts:
        print(part)
        if Q_KEY_RX.match(part):
            q_key = part
            break
    # last '?' (excluding q_key) is IMVP
    q_candidates = [p for p in parts if p.endswith("?") and p != q_key]
    if q_candidates:
        imvp = q_candidates[-1]
    # first non-q, non-question is Section
    for part in parts:
        if part == q_key:
            continue
        if not part.endswith("?"):
            section = part
            break
    if not section:
        non_q = [p for p in parts if p != q_key and not p.endswith("?")]
        if non_q:
            section = sorted(non_q, key=len)[0]
    return q_key, section, imvp


def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    # start after "Request Items" if present
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    L = lines[start:]

    rows: List[Dict] = []
    i = 0
    while i < len(L):
        line = L[i]
        if RFR_RX.search(line):
            q_key, section, imvp_q = extract_meta_from_rfr_header(line)
            responses: List[str] = []
            i += 1
            while i < len(L) and not RFR_RX.search(L[i]):
                cur = L[i]
                if RESP_HDR_RX.search(cur):
                    i += 1
                    block: List[str] = []
                    while (
                        i < len(L)
                        and not RESP_HDR_RX.search(L[i])
                        and not RFR_RX.search(L[i])
                    ):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    m = BRACKETS_RX.fullmatch(resp)  # unwrap <...> if whole block
                    if m:
                        resp = norm(m.group(1))
                    if resp:
                        responses.append(resp)
                    continue
                i += 1

            # ðŸ”’ Guard: only emit if we have IMVP or any response
            if (imvp_q and imvp_q.strip()) or responses:
                rows.append({
                    "IMVP Question": imvp_q or "",
                    "Section": section or "",
                    "rfr": {(q_key or "Q?"): " ".join(responses).strip()},
                    "doctype": "rfr",
                })
            continue
        i += 1
    return rows


def parse_docx_to_rfr_rows(path: str) -> List[Dict]:
    return parse_lines_after_request_items(read_docx_lines(path))


# ----- MERGERS -----
def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    """
    If a row has empty IMVP but has rfr content, merge that rfr into the
    most recent prior row with the SAME Section and a non-empty IMVP.
    Drop the empty-IMVP row afterward.
    """
    out: List[Dict] = []
    last_with_imvp_by_section: dict = {}
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            # empty IMVP; try to merge
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
            else:
                # optional: keep as-is if no target found; or skip entirely
                # Here we skip to avoid stray rows
                pass
    return out


def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    """
    Merge rows with identical non-empty IMVP Question:
     - Combine rfr entries
     - Keep first non-empty Section
    """
    merged: "OrderedDict[str, Dict]" = OrderedDict()
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "",
                "rfr": dict(r.get("rfr") or {}),
                "doctype": "rfr",
            }
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if not merged[imvp]["Section"] and (r.get("Section") or ""):
                merged[imvp]["Section"] = r["Section"]
    return list(merged.values())


# --------- SIMPLE RUN ---------
if __name__ == "__main__":
    DOCX_PATH = "Final RFR .docx"   # <-- your file
    OUT_PATH = "rfr_rows.jsonl"

    rows = parse_docx_to_rfr_rows(DOCX_PATH)
    # 1) fold empty-IMVP rows into previous same-section item
    rows = collapse_empty_imvp_into_previous(rows)
    # 2) merge duplicates by identical IMVP
    rows = merge_rows_by_imvp(rows)

    with open(OUT_PATH, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"Wrote {len(rows)} row(s) to {OUT_PATH}")            if re.search(r"\b(Data|Model|Govern|Develop|Validation|Testing|Documentation)\b", p, re.IGNORECASE):
                section = p
                break
    if not imvp:
        for p in parts:
            if p != rfr_question and p != section and is_question_like(p):
                imvp = p
                break

    return rfr_id, q_key, section, imvp, rfr_question

# ---------- core parser (works on an existing list of lines) ----------
def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    # Start after "Request Items" if present
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    L = [norm(x) for x in lines[start:] if norm(x)]

    rows: List[Dict] = []
    i = 0
    while i < len(L):
        line = L[i]

        # Is this an RFR header?
        if RFR_RX_LINE.search(line) or RFR_START_RX.search(line):
            rfr_id, q_key, section, imvp_q, rfr_question = extract_meta_from_rfr_header(line)
            responses: List[str] = []
            i += 1

            # Prefer formal response blocks, but ALSO capture any orphan lines
            orphan_bucket: List[str] = []

            while i < len(L) and not (RFR_RX_LINE.search(L[i]) or RFR_START_RX.search(L[i])):
                cur = L[i]

                if RESP_HDR_RX.search(cur):
                    # Flush orphan lines first
                    if orphan_bucket:
                        orphan_text = norm(" ".join(orphan_bucket))
                        orphan_text = unwrap_if_surrounded_by_brackets(orphan_text)
                        if orphan_text:
                            responses.append(orphan_text)
                        orphan_bucket = []

                    # Read the named "Modeling Teamâ€™s Response" block
                    i += 1
                    block: List[str] = []
                    while i < len(L) and not RESP_HDR_RX.search(L[i]) and not (RFR_RX_LINE.search(L[i]) or RFR_START_RX.search(L[i])):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    resp = unwrap_if_surrounded_by_brackets(resp)
                    if resp:
                        responses.append(resp)
                    continue

                # Orphan line (belongs to current RFR)
                orphan_line = norm(cur)
                if orphan_line:
                    orphan_bucket.append(orphan_line)
                i += 1

            # Flush trailing orphans
            if orphan_bucket:
                orphan_text = norm(" ".join(orphan_bucket))
                orphan_text = unwrap_if_surrounded_by_brackets(orphan_text)
                if orphan_text:
                    responses.append(orphan_text)

            # Only emit if we have IMVP or any response
            if (imvp_q and imvp_q.strip()) or responses:
                rows.append({
                    "IMVP Question": imvp_q or "",
                    "Section": section or "",
                    "rfr": { (rfr_question or q_key or "Q?"): " ".join(responses).strip() },
                    "doctype": "rfr",
                    "Q_key": q_key or "",
                    "rfr_id": rfr_id or "",
                })
            continue

        i += 1

    return rows

# ---------- optional mergers ----------
def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    """
    If a row has empty IMVP but has rfr content, merge that rfr into the
    most recent prior row with the SAME Section and a non-empty IMVP.
    """
    out: List[Dict] = []
    last_with_imvp_by_section: dict = {}
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
            # else: drop stray rows
    return out

def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    """Merge rows with identical non-empty IMVP; combine rfr maps, keep first non-empty Section."""
    merged: "OrderedDict[str, Dict]" = OrderedDict()
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "",
                "rfr": dict(r.get("rfr") or {}),
                "doctype": "rfr",
                "Q_key": r.get("Q_key", ""),
                "rfr_id": r.get("rfr_id", ""),
            }
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if not merged[imvp]["Section"] and (r.get("Section") or ""):
                merged[imvp]["Section"] = r["Section"]
            # keep first non-empty Q_key/rfr_id (optional: could collect lists)
            if not merged[imvp]["Q_key"] and r.get("Q_key"):
                merged[imvp]["Q_key"] = r["Q_key"]
            if not merged[imvp]["rfr_id"] and r.get("rfr_id"):
                merged[imvp]["rfr_id"] = r["rfr_id"]
    return list(merged.values())

# ---------- convenient public API ----------
def parse_rfr(
    *, 
    docx_path: Optional[str] = None, 
    lines: Optional[List[str]] = None,
    do_merge: bool = True,
    collapse_empty: bool = True,
) -> List[Dict]:
    """
    Parse RFR rows from either `docx_path` or pre-read `lines`.
    - `collapse_empty`: merge orphan rows with empty IMVP into the previous row in the same Section.
    - `do_merge`: merge rows with identical IMVP Question (combines rfr maps).
    """
    if lines is None:
        if not docx_path:
            raise ValueError("Provide either `lines` or `docx_path`.")
        lines = read_docx_lines(docx_path)

    rows = parse_lines_after_request_items(lines)
    if collapse_empty:
        rows = collapse_empty_imvp_into_previous(rows)
    if do_merge:
        rows = merge_rows_by_imvp(rows)
    return rows

# ---------- (optional) flatten helper for tabular export ----------
def flatten_rows(rows: List[Dict]) -> List[Dict]:
    """
    Expand each row's 'rfr' dict into multiple flat rows:
    Columns: rfr_id, Q_key, Section, IMVP Question, Question, Response
    """
    flat: List[Dict] = []
    for r in rows:
        section = r.get("Section", "")
        imvp = r.get("IMVP Question", "")
        q_key = r.get("Q_key", "")
        rfr_id = r.get("rfr_id", "")
        rfr_map = r.get("rfr") or {}
        for question, response in rfr_map.items():
            flat.append({
                "rfr_id": rfr_id,
                "Q_key": q_key,
                "Section": section,
                "IMVP Question": imvp,
                "Question": question,     # full "Q#: â€¦" text
                "Response": response,     # Modeling Teamâ€™s Response (combined)
            })
    return flat

# --------- example usage (comment out in library use) ---------
if __name__ == "__main__":
    # Example A: if you already have the list of lines from read_docx_lines
    # lines_list = [...]
    # rows = parse_rfr(lines=lines_list)

    # Example B: parse directly from a .docx
    # rows = parse_rfr(docx_path="Final RFR .docx")

    # Save JSONL
    # with open("rfr_rows.jsonl", "w", encoding="utf-8") as f:
    #     for r in rows:
    #         f.write(json.dumps(r, ensure_ascii=False) + "\n")

    # Optional: save flattened CSV-like JSON
    # flat = flatten_rows(rows)
    # with open("rfr_rows_flat.json", "w", encoding="utf-8") as f:
    #     json.dump(flat, f, ensure_ascii=False, indent=2)
    pass
