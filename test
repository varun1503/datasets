import streamlit as st
import requests
import os

API_BASE_URL = "http://127.0.0.1:8080"  # Your FastAPI endpoint

st.set_page_config(page_title="RAG App", layout="wide")
st.markdown("<h1 style='text-align: center;'>RAG Chat Interface</h1>", unsafe_allow_html=True)

if "messages" not in st.session_state:
    st.session_state.messages = []

if "retrieved_docs" not in st.session_state:
    st.session_state.retrieved_docs = []

# ---------- Layout Columns ----------
col1, col2, col3 = st.columns([1, 2, 1])

# ---------- Column 1: Upload + Settings ----------
with col1:
    st.subheader("1. Upload Document")
    uploaded_file = st.file_uploader("Upload a file", type=["pdf", "txt", "docx"])
    chunking_type = st.selectbox("Select Chunking Type", ["recursive", "semantic", "automerger"])
    index_id_upload = st.text_input("Index ID for Upload", value="df101")

    if uploaded_file:
        with open(uploaded_file.name, "wb") as f:
            f.write(uploaded_file.getbuffer())
        document_path = os.path.abspath(uploaded_file.name)

        if st.button("Upload and Chunk"):
            payload = {
                "document_path": document_path,
                "chunking_type": chunking_type,
                "index_id": index_id_upload
            }
            try:
                response = requests.post(f"{API_BASE_URL}/upload/documents", json=payload)
                if response.status_code == 200:
                    st.success("Document uploaded and chunked successfully!")
                else:
                    st.error(f"Upload failed: {response.text}")
            except Exception as e:
                st.error(f"Error: {e}")

    st.markdown("---")
    st.subheader("2. Settings")

    faiss_index_id = st.text_input("Faiss Index ID", value="df101")

    st.markdown("### Model")
    model_options = {
        "3": {"name": "OpenAI GPT-4.0", "logo": "https://upload.wikimedia.org/wikipedia/commons/0/04/OpenAI_Logo.svg"},
        "1": {"name": "Other Model", "logo": "https://via.placeholder.com/40x40.png?text=AI"}
    }

    selected_model_id = st.selectbox("Model ID", options=list(model_options.keys()), format_func=lambda x: model_options[x]["name"])
    st.image(model_options[selected_model_id]["logo"], width=50, caption=model_options[selected_model_id]["name"])

    top_k = st.slider("Top K Docs", 1, 10, 5)

# ---------- Column 2: Chat Interface ----------
with col2:
    st.subheader("Chat")

    dummy_qs = ["Which tools do you have access to?", "Tell me about yourself", "What's your special skill?"]
    st.markdown("**Try a sample question:**")
    st.write(dummy_qs)

    chat_placeholder = st.container()
    input_placeholder = st.empty()  # This stays pinned at bottom

    # Render chat from bottom-up
    with chat_placeholder:
        for msg in reversed(st.session_state.messages):
            if msg["role"] == "user":
                st.markdown(f"**You:** {msg['content']}")
            else:
                st.markdown(f"**Assistant:** {msg['content']}")

    # User input stays here at bottom
    with input_placeholder:
        user_input = st.chat_input("Ask a question...")

    if user_input:
        # Show user message first
        st.session_state.messages.append({"role": "user", "content": user_input})

        # Send API request
        try:
            payload = {
                "query": user_input,
                "top_k": top_k,
                "index_id": faiss_index_id,
                "generative_model_id": selected_model_id
            }

            response = requests.post(f"{API_BASE_URL}/retrieve_and_generate", json=payload)

            if response.status_code == 200:
                result = response.json()
                answer = result.get("generated_response", "No response.")
                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.session_state.retrieved_docs = result.get("retrieved_documents", [])
            else:
                st.session_state.messages.append({"role": "assistant", "content": f"Error: {response.text}"})

        except Exception as e:
            st.session_state.messages.append({"role": "assistant", "content": f"Exception: {e}"})


# ---------- Column 3: Retrieved Docs ----------
with col3:
    st.subheader("Retrieved Documents")
    if st.session_state.retrieved_docs:
        for doc in st.session_state.retrieved_docs:
            st.markdown(f"**Page {doc['page']} | Source: {doc['source']}**")
            st.write(doc["content"])
            st.markdown("---")
