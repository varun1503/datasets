# =========================================================
# JUPYTER NOTEBOOK â€“ VERSION-SAFE FINAL CODE
# =========================================================

import asyncio
from typing import List

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompt_values import ChatPromptValue

from agent_framework import ChatAgent
from agent_framework.messages import ChatMessage, Role, TextContent


# =========================================================
# HELPER (VERSION SAFE)
# =========================================================
def get_text(m: ChatMessage) -> str:
    if hasattr(m, "content") and m.content:
        return m.content.value
    if hasattr(m, "contents") and m.contents:
        return m.contents[0].value
    return ""


# =========================================================
# ORG STANDARD MODEL FACTORY
# =========================================================
def model(version: str):
    return MyCustomLLM(version)


# =========================================================
# CUSTOM LLM (ChatPromptValue ONLY)
# =========================================================
class MyCustomLLM:
    def __init__(self, version: str):
        self.version = version

    def invoke(self, prompt_value: ChatPromptValue) -> ChatMessage:
        print(f"\nðŸ”µ LLM model({self.version}) INVOKED WITH PROMPT:\n")
        print(prompt_value.to_string())

        # IMPORTANT: use contents (list)
        return ChatMessage(
            role=Role.ASSISTANT,
            contents=[
                TextContent(
                    value="Hello ðŸ‘‹ This response came from model('3')"
                )
            ],
        )


# =========================================================
# CUSTOM CHAT CLIENT (FRAMEWORK COMPATIBLE)
# =========================================================
class MyChatClient:
    async def get_response(
        self,
        messages: List[ChatMessage],
        *,
        tools=None,
        **kwargs,
    ) -> ChatMessage:
        return await self.invoke(messages, tools=tools, **kwargs)

    async def invoke(
        self,
        messages: List[ChatMessage],
        *,
        tools=None,
        **kwargs,
    ) -> ChatMessage:

        # ðŸ”‘ SAFE extraction for YOUR framework version
        prompt_template = ChatPromptTemplate.from_messages(
            [(m.role, get_text(m)) for m in messages]
        )

        prompt_value = prompt_template.format_prompt()

        llm = model("3")
        return llm.invoke(prompt_value)


# =========================================================
# GREETING AGENT
# =========================================================
class GreetingAgent(ChatAgent):
    def __init__(self):
        super().__init__(
            name="GreetingAgent",
            chat_client=MyChatClient(),
            instructions="You are a friendly greeting assistant.",
        )


# =========================================================
# RUN
# =========================================================
async def main():
    agent = GreetingAgent()
    response = await agent.run("Hi")

    print("\nðŸŸ¢ FINAL RESPONSE TEXT:\n")

    # SAFE printing
    print(get_text(response.messages[0]))

await main()
