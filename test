import re
import json
import unicodedata
import os
import pandas as pd
from typing import List, Dict, Tuple, Optional
from docx import Document
from collections import OrderedDict
from docx.oxml.ns import qn
from docx.table import Table
from docx.text.paragraph import Paragraph


def norm(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()


def group_blocks_from_list(
    lines: List[str],
    start_rx: re.Pattern,
    stop_rx: Optional[re.Pattern] = None,
    stop_substrings: Optional[List[str]] = None,
    joiner: str = " ",
    include_stop_line: bool = False,
) -> List[Tuple[int, int, str]]:
    """
    Group consecutive lines from a list into blocks.
    Returns a list of tuples (start_idx, end_idx, grouped_text).
    """
    stop_substrings = stop_substrings or []
    grouped_blocks = []
    buf = []
    capturing = False
    start_idx = 0

    def flush(end_idx):
        nonlocal buf
        if buf:
            grouped_text = joiner.join(s.strip() for s in buf if s.strip())
            grouped_blocks.append((start_idx, end_idx, grouped_text))
            buf = []

    for i, line in enumerate(lines):
        s = (line or "").strip()
        if start_rx.search(s):
            if capturing:
                flush(i - 1)
            capturing = True
            start_idx = i
            buf = [s]
            continue

        if not capturing:
            continue

        buf.append(s)

        stop_hit = False
        if stop_rx and stop_rx.search(s):
            stop_hit = True
        elif any(sub in s for sub in stop_substrings):
            stop_hit = True

        if stop_hit:
            if not include_stop_line:
                buf.pop()
                flush(i - 1)
            else:
                flush(i)
            capturing = False

    if capturing:
        flush(len(lines) - 1)

    return grouped_blocks


def replace_blocks_in_lines(lines: List[str], grouped_blocks: List[Tuple[int, int, str]]) -> List[str]:
    """
    Replace original RFR block lines with their grouped version, preserving sequence.
    """
    replaced = []
    i = 0
    block_map = {start: (end, text) for start, end, text in grouped_blocks}

    while i < len(lines):
        if i in block_map:
            end_idx, text = block_map[i]
            replaced.append(text)
            i = end_idx + 1
        else:
            replaced.append(lines[i])
            i += 1
    return replaced


def read_docx_lines(path: str) -> List[str]:
    doc = Document(path)
    lines: List[str] = []
    # Walk through document body in order
    for child in doc.element.body.iterchildren():
        if child.tag == qn("w:p"):  # Paragraph
            p = Paragraph(child, doc)
            t = norm(p.text)
            if t:
                lines.append(t)
        elif child.tag == qn("w:tbl"):  # Table
            tbl = Table(child, doc)
            for row in tbl.rows:
                row_text = []
                for cell in row.cells:
                    for p in cell.paragraphs:
                        t = norm(p.text)
                        if t:
                            row_text.append(t)
                if row_text:
                    lines.append(" | ".join(row_text))  # Optional: format table row nicely
    blocks = group_blocks_from_list(lines, start_rx=RFR_RX, stop_substrings=STOP_SUBS, include_stop_line=False)
    final_lines = replace_blocks_in_lines(lines, blocks)
    return final_lines


# ---------- REGEX PATTERNS ----------
REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)
RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)  # tolerant
BRACKETS_RX = re.compile(r"<\s*([^>]+?)\s*>")
Q_KEY_RX = re.compile(r"^\s*Q\d+\s*:\s*", re.IGNORECASE)
RESP_HDR_RX = re.compile(r"Modeling Team['']?s Response", re.IGNORECASE)
TEST_TAG_RX = re.compile(r"^Test\s*(\w+)", re.IGNORECASE)  # NEW: for test tag detection

STOP_SUBS = ["Modeling Team's Response", "Modeling Team's Response"]


def extract_meta_from_rfr_header(line: str) -> Tuple[str, str, str]:
    q_key = ""
    section = ""
    imvp = ""
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    # Q may also end with '?', so detect by prefix not by '?'
    for part in parts:
        if Q_KEY_RX.match(part):
            q_key = part
            break
    # last '?' (excluding q_key) is IMVP
    q_candidates = [p for p in parts if p.endswith("?") and p != q_key]
    if q_candidates:
        imvp = q_candidates[-1]
    # first non-q, non-question is Section
    for part in parts:
        if part == q_key:
            continue
        if not part.endswith("?"):
            section = part
            break
    if not section:
        non_q = [p for p in parts if p != q_key and not p.endswith("?")]
        if non_q:
            section = sorted(non_q, key=len)[0]
    return q_key, section, imvp


def extract_test_tag(line: str) -> Optional[str]:
    """NEW FUNCTION: Extract test tag from line"""
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    for part in parts:
        m = TEST_TAG_RX.match(part)
        if m:
            tag_value = m.group(1).lower()
            return f"tests{tag_value}"
    return None


def clean_greater_than(lines):
    return [re.sub(r'>.*$', '', s).strip() for s in lines]


def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    # start after "Request Items" if present
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    L = lines[start:]
    rows: List[Dict] = []
    i = 0
    while i < len(L):
        line = L[i]
        if RFR_RX.search(line):
            q_key, section, imvp_q = extract_meta_from_rfr_header(line)
            test_tag = extract_test_tag(line)  # NEW: extract test tag
            responses: List[str] = []
            i += 1
            while i < len(L) and not RFR_RX.search(L[i]):
                cur = L[i]
                if RESP_HDR_RX.search(cur):
                    i += 1
                    block: List[str] = []
                    while (
                        i < len(L)
                        and not RESP_HDR_RX.search(L[i])
                        and not RFR_RX.search(L[i])
                    ):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    m = BRACKETS_RX.fullmatch(resp)  # unwrap <...> if whole block
                    if m:
                        resp = norm(m.group(1))
                    if resp:
                        responses.append(resp)
                    continue
                i += 1
            # Guard: only emit if we have IMVP or any response
            responses = clean_greater_than(responses)
            if (imvp_q and imvp_q.strip()) or responses:
                row = {
                    "IMVP Question": imvp_q or "",
                    "Section": section or "",
                    "rfr": {(q_key or "Q?"): " ".join(responses).strip()},
                }
                # NEW: Add test tag if found
                if test_tag:
                    row[test_tag] = imvp_q or ""
                rows.append(row)
            continue
        i += 1
    return rows


def parse_docx_to_rfr_rows(path: str) -> List[Dict]:
    return parse_lines_after_request_items(read_docx_lines(path))


# ----- MERGERS -----
def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    """
    If a row has empty IMVP but has rfr content, merge that rfr into the
    most recent prior row with the SAME Section and a non-empty IMVP.
    Drop the empty-IMVP row afterward.
    """
    out: List[Dict] = []
    last_with_imvp_by_section: dict = {}
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            # empty IMVP; try to merge
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
            else:
                # optional: keep as-is if no target found; or skip entirely
                # Here we skip to avoid stray rows
                pass
    return out


def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    """
    Merge rows with identical non-empty IMVP Question:
    - Combine rfr entries
    - Keep first non-empty Section
    """
    merged: "OrderedDict[str, Dict]" = OrderedDict()
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "",
                "rfr": dict(r.get("rfr") or {})
            }
            # NEW: Copy test tag keys
            for key in r.keys():
                if key.startswith("tests"):
                    merged[imvp][key] = r[key]
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if not merged[imvp]["Section"] and (r.get("Section") or ""):
                merged[imvp]["Section"] = r["Section"]
            # NEW: Update test tag keys
            for key in r.keys():
                if key.startswith("tests"):
                    merged[imvp][key] = r[key]
    return list(merged.values())


def convert_csv(rows, document_path):
    file_name = os.path.basename(document_path)
    data = {"finding": rows}
    df = pd.DataFrame(data)
    df["file name"] = file_name
    df["type"] = "rfr"
    return df


def validate_rows(rows: List[Dict]) -> List[Dict]:
    """
    Strict rules:
    - IMVP Question must exist and end with '?'
    - rfr map must have exactly one key and that key must equal the IMVP Question
    - response must be non-empty
    If a row uses 'Q3' (or 'Q?') as the rfr key because the question is missing,
    raise an error.
    """
    for idx, r in enumerate(rows, start=1):
        imvp = (r.get("IMVP Question") or "").strip()
        rfr = r.get("rfr") or {}
        if not imvp or not imvp.endswith("?"):
            # explicitly fail when the document has no question
            # even if we detected Q3
            qkeys = list(rfr.keys())
            raise ValueError(
                f"Document is not formatted correctly: row {idx} missing IMVP question "
                f"(found rfr keys={qkeys}). Header must include a <...?> block."
            )

        # must have exactly one rfr key, and it must equal the question text
        if not isinstance(rfr, dict) or len(rfr) != 1:
            raise ValueError(
                f"Document is not formatted correctly: row {idx} has invalid rfr map: {rfr}"
            )
        (k, v) = next(iter(rfr.items()))
        if k.strip() in {"Q?", "Q3", "Q1", "Q2", "Q4", "Q5"} and k.strip() != imvp:
            raise ValueError(
                f"Document is not formatted correctly: row {idx} uses Q-ID '{k}' "
                f"instead of the RFR question.\n IMVP: {imvp}\n rfr key: {k}"
            )
        if not (v or "").strip():
            raise ValueError(
                f"Document is not formatted correctly: row {idx} has empty Modeling Team response for '{imvp}'"
            )

    return rows


# --------- SIMPLE RUN ---------

if __name__ == "__main__":
    DOCX_PATH = "FinalRFRorignal.docx"
    OUT_PATH = "rfr_rows.json"

    rows = parse_docx_to_rfr_rows(DOCX_PATH)

    # 1) fold empty-IMVP rows into previous same-section item
    rows = validate_rows(rows)
    rows = collapse_empty_imvp_into_previous(rows)

    # 2) merge duplicates by identical IMVP
    rows = merge_rows_by_imvp(rows)

    df = convert_csv(rows, DOCX_PATH)
    print(df)

    with open(OUT_PATH, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"Wrote {len(rows)} row(s) to {OUT_PATH}")
