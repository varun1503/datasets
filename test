from docx import Document
from docx.oxml.ns import qn
from docx.text.paragraph import Paragraph
import os
import uuid
import base64
import re

# Namespaces for DOCX XML parsing
NSMAP = {
    'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main',
    'a': 'http://schemas.openxmlformats.org/drawingml/2006/main',
    'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships'
}

def generate_id():
    return str(uuid.uuid4())

def get_cell_text(cell):
    paragraphs = [Paragraph(p, None).text.strip() for p in cell.findall('.//w:p', namespaces=NSMAP)]
    return "\n".join(p for p in paragraphs if p)

def extract_section_number(text):
    match = re.match(r"^((\d+\.)+)", text.strip())
    return match.group(1).strip() if match else None

def encode_image(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

def extract_ordered_docx_content(file_path, save_images=True, image_output_dir='images'):
    doc = Document(file_path)
    body = doc._element.body
    ordered_content = []
    parent_stack = []

    if save_images:
        os.makedirs(image_output_dir, exist_ok=True)

    def get_current_parent():
        return parent_stack[-1] if parent_stack else None

    for child in body.iterchildren():
        tag = child.tag

        # Paragraph Handling
        if tag == qn('w:p'):
            para = Paragraph(child, doc)
            text = para.text.strip()
            if not text:
                continue
            style = para.style.name if para.style else ""

            # Heading detection
            if style.startswith("Heading"):
                level = int(style.replace("Heading", "").strip() or "1")
                heading_id = generate_id()
                section_number = extract_section_number(text)
                heading_item = {
                    'id': heading_id,
                    'type': 'heading',
                    'text': text,
                    'section_number': section_number,
                    'level': level,
                    'child_ids': []
                }

                while parent_stack and parent_stack[-1]['level'] >= level:
                    parent_stack.pop()

                parent = get_current_parent()
                heading_item['parent_id'] = parent['id'] if parent else None
                if parent:
                    parent['child_ids'].append(heading_id)

                parent_stack.append(heading_item)
                ordered_content.append(heading_item)
                continue

            # Normal Paragraph
            para_id = generate_id()
            parent = get_current_parent()
            para_item = {
                'id': para_id,
                'type': 'paragraph',
                'text': text,
                'parent_id': parent['id'] if parent else None
            }
            if parent:
                parent['child_ids'].append(para_id)
            ordered_content.append(para_item)

            # Embedded images within paragraph
            for drawing in child.findall('.//w:drawing', namespaces=NSMAP):
                blip = drawing.find('.//a:blip', namespaces=NSMAP)
                if blip is not None:
                    r_embed = blip.attrib.get(qn('r:embed'))
                    image_part = doc.part.related_parts.get(r_embed)
                    if image_part:
                        content_type = image_part.content_type
                        ext = content_type.split('/')[-1].lower()
                        allowed_exts = ['png', 'jpeg', 'jpg']

                        if ext in allowed_exts:
                            image_id = generate_id()
                            image_label = f"Image_{image_id[:8]}"
                            image_filename = f"{image_label}.{ext}"

                            if save_images:
                                image_path = os.path.join(image_output_dir, image_filename)
                                with open(image_path, "wb") as f:
                                    f.write(image_part.blob)

                                base64_image = encode_image(image_path)
                                # Placeholder for AI model usage
                                prompt_image = "Prompt().image_insight_prompt()"
                                input_nodes = {"base_64_encoded_image": base64_image}
                                llm_output = "llm_output_model_invoke()"  # Replace with real call

                            image_item = {
                                'id': image_id,
                                'type': 'image',
                                'label': image_filename,
                                'image_context': llm_output,
                                'parent_id': parent['id'] if parent else None
                            }
                            if parent:
                                parent['child_ids'].append(image_id)
                            ordered_content.append(image_item)

        # Table Handling
        elif tag == qn('w:tbl'):
            table_data = []
            rows = child.findall('.//w:tr', namespaces=NSMAP)
            for row in rows:
                row_data = []
                for cell in row.findall('.//w:tc', namespaces=NSMAP):
                    row_data.append(get_cell_text(cell))
                table_data.append(row_data)

            table_id = generate_id()
            parent = get_current_parent()
            table_item = {
                'id': table_id,
                'type': 'table',
                'data': table_data,
                'parent_id': parent['id'] if parent else None
            }
            if parent:
                parent['child_ids'].append(table_id)
            ordered_content.append(table_item)

    return ordered_content
