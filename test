Absolutely!
Hereâ€™s how to save your batch_payload to a file, and then how to load and send it in another script or notebook.


---

1. Save batch_payload to a local JSON file

Add this right after you create batch_payload:

import json

# Save batch_payload to a file (e.g., 'batch_payload.json')
with open("batch_payload.json", "w", encoding="utf-8") as f:
    json.dump(batch_payload, f, ensure_ascii=False, indent=2)
print("Saved batch_payload.json")


---

2. Load and send in a separate script (or notebook cell)

You can use this in a new Python file, script, or notebook:

import json
import requests

# Load the batch payload
with open("batch_payload.json", "r", encoding="utf-8") as f:
    payload = json.load(f)

# Change the URL to your actual endpoint!
url = "http://localhost:8000/ingest-batch"

response = requests.post(
    url,
    json=payload,
    headers={"Content-Type": "application/json"}
)

print("Status code:", response.status_code)
print("Response:", response.text)


---

Summary Table


---

Let me know if you want a version using CSV, or a custom filename/path!

