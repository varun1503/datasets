import re
import json
import unicodedata
import os
import pandas as pd
from typing import List, Dict, Tuple, Optional
from collections import OrderedDict
from docx import Document
from docx.oxml.ns import qn
from docx.table import Table
from docx.text.paragraph import Paragraph

# ===================== REGEX =====================
RFR_RX = re.compile(r"\bRFR\s*\d+\b", re.IGNORECASE)
REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)
Q_KEY_RX = re.compile(r"^\s*Q\d+\s*:", re.IGNORECASE)
RESP_HDR_RX = re.compile(r"Modeling Team[â€™']?s Response", re.IGNORECASE)
BRACKETS_RX = re.compile(r"<\s*([^>]+?)\s*>")
STOP_SUBS = ["[Modeling Teamâ€™s Response]", "[", "Modeling Teamâ€™s Response"]

# ===================== HELPERS =====================
def norm(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()

def clean_greater_than(lines: List[str]) -> List[str]:
    return [re.sub(r'>.*$', '', s).strip() for s in lines if s.strip()]

# ===================== DOCX READER =====================
def read_docx_lines(path: str) -> List[str]:
    doc = Document(path)
    lines: List[str] = []

    for child in doc.element.body.iterchildren():
        if child.tag == qn("w:p"):
            p = Paragraph(child, doc)
            t = norm(p.text)
            if t:
                lines.append(t)

        elif child.tag == qn("w:tbl"):
            tbl = Table(child, doc)
            for row in tbl.rows:
                row_text = []
                for cell in row.cells:
                    for p in cell.paragraphs:
                        t = norm(p.text)
                        if t:
                            row_text.append(t)
                if row_text:
                    lines.append(" | ".join(row_text))

    return lines

# ===================== BLOCK GROUPING =====================
def group_blocks_from_list(
    lines: List[str],
    start_rx: re.Pattern,
    stop_substrings: Optional[List[str]] = None,
) -> List[Tuple[int, int, str]]:
    stop_substrings = stop_substrings or []
    grouped = []
    buf = []
    capturing = False
    start_idx = 0

    def flush(end_idx):
        nonlocal buf
        if buf:
            grouped.append((start_idx, end_idx, " ".join(buf)))
            buf = []

    for i, line in enumerate(lines):
        s = line.strip()

        if start_rx.search(s):
            if capturing:
                flush(i - 1)
            capturing = True
            start_idx = i
            buf = [s]
            continue

        if not capturing:
            continue

        buf.append(s)

        if any(sub in s for sub in stop_substrings):
            buf.pop()
            flush(i - 1)
            capturing = False

    if capturing:
        flush(len(lines) - 1)

    return grouped

def replace_blocks_in_lines(lines, blocks):
    out = []
    i = 0
    block_map = {s: (e, t) for s, e, t in blocks}

    while i < len(lines):
        if i in block_map:
            e, t = block_map[i]
            out.append(t)
            i = e + 1
        else:
            out.append(lines[i])
            i += 1
    return out

# ===================== META EXTRACTION =====================
def extract_meta_from_rfr_header(line: str) -> Tuple[str, str, str]:
    """
    Handles:
    - IMVP with '?'
    - IMVP without '?'
    - Correct section extraction
    """
    q_key = ""
    section = ""
    imvp = ""

    parts = [norm(x) for x in BRACKETS_RX.findall(line)]

    # Qx and IMVP
    for part in parts:
        if Q_KEY_RX.match(part):
            q_key = part.split(":", 1)[0].strip()   # Q2
            imvp = part.split(":", 1)[1].strip() if ":" in part else part
            break

    # Section
    for part in parts:
        if not Q_KEY_RX.match(part):
            section = part
            break

    return q_key, section, imvp

# ===================== CORE PARSER =====================
def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break

    L = lines[start:]
    rows = []
    i = 0

    while i < len(L):
        line = L[i]

        if RFR_RX.search(line):
            q_key, section, imvp = extract_meta_from_rfr_header(line)
            responses = []
            i += 1

            while i < len(L) and not RFR_RX.search(L[i]):
                if RESP_HDR_RX.search(L[i]):
                    i += 1
                    block = []
                    while i < len(L) and not RESP_HDR_RX.search(L[i]) and not RFR_RX.search(L[i]):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    m = BRACKETS_RX.fullmatch(resp)
                    if m:
                        resp = norm(m.group(1))
                    if resp:
                        responses.append(resp)
                    continue
                i += 1

            responses = clean_greater_than(responses)

            if imvp or responses:
                rows.append({
                    "IMVP Question": imvp,
                    "Section": section,
                    "rfr": {q_key or "Q?": " ".join(responses).strip()}
                })
            continue
        i += 1

    return rows

# ===================== CSV CONVERTER =====================
def convert_csv(rows, document_path):
    file_name = os.path.basename(document_path)
    df = pd.DataFrame(rows)
    df["file name"] = file_name
    df["type"] = "rfr"
    return df

# ===================== VALIDATION =====================
def validate_rows(rows: List[Dict]) -> List[Dict]:
    for idx, r in enumerate(rows, start=1):
        imvp = (r.get("IMVP Question") or "").strip()
        rfr = r.get("rfr") or {}

        if not imvp:
            raise ValueError(
                f"Row {idx} missing IMVP Question. Expected <Qx: ...> in RFR header."
            )

        if not isinstance(rfr, dict) or not rfr:
            raise ValueError(
                f"Row {idx} has invalid rfr structure: {rfr}"
            )

        (_, v) = next(iter(rfr.items()))
        if not v.strip():
            raise ValueError(
                f"Row {idx} has empty Modeling Team response."
            )

    return rows

# ===================== ENTRY POINT =====================
def parse_docx_to_rfr_rows(path: str) -> List[Dict]:
    lines = read_docx_lines(path)
    blocks = group_blocks_from_list(lines, RFR_RX, STOP_SUBS)
    lines = replace_blocks_in_lines(lines, blocks)
    rows = parse_lines_after_request_items(lines)
    return validate_rows(rows)

# ===================== RUN =====================
if __name__ == "__main__":
    DOCX_PATH = "sample_RFR.docx"
    OUT_JSON = "rfr_rows.json"
    OUT_CSV = "rfr_rows.csv"

    rows = parse_docx_to_rfr_rows(DOCX_PATH)

    with open(OUT_JSON, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    df = convert_csv(rows, DOCX_PATH)
    df.to_csv(OUT_CSV, index=False)

    print(f"âœ… Parsed {len(rows)} RFR rows successfully")                row_text = []
                for cell in row.cells:
                    for p in cell.paragraphs:
                        t = norm(p.text)
                        if t:
                            row_text.append(t)
                if row_text:
                    lines.append(" | ".join(row_text))

    # Group RFR blocks
    RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)
    STOP_SUBS = ["[Modeling Team's Response]", "[", "Modeling Team's Response"]
    blocks = group_blocks_from_list(lines, start_rx=RFR_RX, stop_substrings=STOP_SUBS, include_stop_line=False)
    final_lines = replace_blocks_in_lines(lines, blocks)

    return final_lines


# Patterns
REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)
RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)
BRACKETS_RX = re.compile(r"<\s*([^>]+?)\s*>")
Q_KEY_RX = re.compile(r"^\s*Q\d+\s*:\s*", re.IGNORECASE)
RESP_HDR_RX = re.compile(r"Modeling Team['']?s Response", re.IGNORECASE)
TEST_TAG_RX = re.compile(r"^Test\s*(\w+)", re.IGNORECASE)


def extract_meta_from_rfr_header(line: str) -> Tuple[str, str, str]:
    """
    Extract metadata from RFR header with improved logic:
    - Handles missing '?' in IMVP questions
    - Better section extraction
    """
    q_key = ""
    section = ""
    imvp = ""
    
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    
    if not parts:
        return q_key, section, imvp
    
    # Extract Q key (e.g., "Q2:")
    for part in parts:
        if Q_KEY_RX.match(part):
            q_key = part
            break
    
    # NEW LOGIC: Better IMVP extraction
    # Look for longest bracketed content that's not Q-key and not short tags
    candidates = [p for p in parts if p != q_key and len(p) > 20]
    
    # Prefer parts ending with '?' but accept longest if none found
    question_parts = [p for p in candidates if p.endswith("?")]
    if question_parts:
        imvp = max(question_parts, key=len)
    elif candidates:
        # If no '?' found, take the longest substantial text
        imvp = max(candidates, key=len)
    
    # Extract section: look for short descriptive tags
    section_candidates = [
        p for p in parts 
        if p != q_key 
        and p != imvp 
        and len(p) < 50 
        and not p.endswith("?")
    ]
    
    # Common section patterns
    section_keywords = ["validation", "data", "model", "performance", "documentation", "testing"]
    for part in section_candidates:
        if any(keyword in part.lower() for keyword in section_keywords):
            section = part
            break
    
    # If no section found yet, take first short non-question part
    if not section and section_candidates:
        section = section_candidates[0]
    
    return q_key, section, imvp


def extract_test_tag(line: str) -> Optional[str]:
    """Extract test tag from line."""
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    for part in parts:
        m = TEST_TAG_RX.match(part)
        if m:
            tag_value = m.group(1).lower()
            return f"test{tag_value}"
    return None


def clean_greater_than(lines: List[str]) -> List[str]:
    """Remove trailing '>' from lines."""
    return [re.sub(r'>.*$', '', s).strip() for s in lines]


def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    """Parse lines into structured RFR rows."""
    # Find start after "Request Items"
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    
    L = lines[start:]
    rows: List[Dict] = []
    i = 0
    
    while i < len(L):
        line = L[i]
        if RFR_RX.search(line):
            q_key, section, imvp_q = extract_meta_from_rfr_header(line)
            test_tag = extract_test_tag(line)
            
            # Extract RFR number for fallback Q-key
            rfr_match = re.search(r"RFR\s*(\d+)", line, re.IGNORECASE)
            rfr_num = rfr_match.group(1) if rfr_match else "?"
            
            # If no Q-key found, create one from RFR number
            if not q_key:
                q_key = f"Q{rfr_num}:"
            
            responses: List[str] = []
            i += 1
            
            # Collect responses
            while i < len(L) and not RFR_RX.search(L[i]):
                cur = L[i]
                if RESP_HDR_RX.search(cur):
                    i += 1
                    block: List[str] = []
                    while (
                        i < len(L)
                        and not RESP_HDR_RX.search(L[i])
                        and not RFR_RX.search(L[i])
                    ):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    # Unwrap <...> if entire block is wrapped
                    m = BRACKETS_RX.fullmatch(resp)
                    if m:
                        resp = norm(m.group(1))
                    if resp:
                        responses.append(resp)
                    continue
                i += 1
            
            responses = clean_greater_than(responses)
            
            # Build row - always include if we have IMVP or responses
            if imvp_q or responses:
                row = {
                    "IMVP Question": imvp_q or "",
                    "Section": section or "N/A",
                    "rfr": {q_key: " ".join(responses).strip()}
                }
                if test_tag:
                    row[test_tag] = imvp_q or ""
                rows.append(row)
            continue
        i += 1
    
    return rows


def parse_docx_to_rfr_rows(path: str) -> List[Dict]:
    """Main entry point: parse DOCX to RFR rows."""
    return parse_lines_after_request_items(read_docx_lines(path))


def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    """Merge rows with empty IMVP into previous row (same section)."""
    out: List[Dict] = []
    last_with_imvp_by_section: dict = {}
    
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            # Empty IMVP; try to merge
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
            # Skip rows that can't be merged
    
    return out


def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    """Merge rows with identical IMVP questions."""
    merged: "OrderedDict[str, Dict]" = OrderedDict()
    
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "N/A",
                "rfr": dict(r.get("rfr") or {})
            }
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if merged[imvp]["Section"] == "N/A" and r.get("Section"):
                merged[imvp]["Section"] = r["Section"]
    
    return list(merged.values())


def flatten_rfr_for_csv(rows: List[Dict]) -> List[Dict]:
    """Flatten rfr dict into separate columns for CSV."""
    flattened = []
    for r in rows:
        base = {
            "IMVP Question": r.get("IMVP Question", ""),
            "Section": r.get("Section", "N/A")
        }
        
        # Add test tags if present
        for key in r:
            if key.startswith("test"):
                base[key] = r[key]
        
        # Flatten rfr dict
        rfr_dict = r.get("rfr", {})
        for q_key, response in rfr_dict.items():
            row_copy = base.copy()
            row_copy["Q_Key"] = q_key
            row_copy["Response"] = response
            flattened.append(row_copy)
    
    return flattened


def convert_csv(rows: List[Dict], document_path: str) -> pd.DataFrame:
    """Convert rows to DataFrame with metadata."""
    file_name = os.path.basename(document_path)
    
    # Flatten for CSV
    flattened = flatten_rfr_for_csv(rows)
    
    df = pd.DataFrame(flattened)
    df["file_name"] = file_name
    df["type"] = "rfr"
    
    return df


def save_outputs(rows: List[Dict], document_path: str, json_path: str = None, csv_path: str = None):
    """Save both JSON and CSV outputs."""
    base_name = os.path.splitext(os.path.basename(document_path))[0]
    
    # Save JSON
    if json_path is None:
        json_path = f"{base_name}_rfr_output.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(rows, f, ensure_ascii=False, indent=2)
    print(f"âœ“ Saved JSON: {json_path} ({len(rows)} rows)")
    
    # Save CSV
    if csv_path is None:
        csv_path = f"{base_name}_rfr_output.csv"
    df = convert_csv(rows, document_path)
    df.to_csv(csv_path, index=False, encoding="utf-8")
    print(f"âœ“ Saved CSV: {csv_path} ({len(df)} rows)")
    
    return json_path, csv_path


if __name__ == "__main__":
    DOCX_PATH = "sample_RFR.docx"
    
    # Parse document
    rows = parse_docx_to_rfr_rows(DOCX_PATH)
    
    print(f"\nðŸ“„ Parsed {len(rows)} initial rows")
    
    # Optional: Apply merging logic
    # rows = collapse_empty_imvp_into_previous(rows)
    # rows = merge_rows_by_imvp(rows)
    
    # Save outputs
    json_file, csv_file = save_outputs(rows, DOCX_PATH)
    
    # Display sample
    print("\nðŸ“‹ Sample output:")
    print(json.dumps(rows[0] if rows else {}, indent=2, ensure_ascii=False))
