import uuid
import logging
from typing import Dict, List, Any, Tuple

logger = logging.getLogger(__name__)

class YourChunkingWrapper:
    # … your __init__ and other methods …

    def create_chunks(
        self,
        data: Dict[str, List[Dict[str, Any]]],
        pss: bool = True
    ) -> List[Dict[str, Any]]:
        """
        Process documents and create chunks.

        Args:
          data: mapping from filename -> list of page-dicts, each with
                'page_content' and 'metadata'.
          pss: if False, skip all chunking and just output each page as a
               single chunk (in AutoMerger’s dict format).
        """
        try:
            for filename, pages in data.items():
                if pss:
                    # full Automerger recursive chunking
                    chunks = self._process_document(pages, filename)
                else:
                    # NO chunking: emit each page as one chunk
                    chunks = []
                    for page in pages:
                        doc_id = str(uuid.uuid4())
                        md = page.get("metadata", {}).copy()
                        md.update({
                            "doc_id": doc_id,
                            "file_name": filename,
                            "level": 0,
                            "type": "doc",
                            "parent_node": None,
                            "prev_node": None,
                            "next_node": None,
                            "child_nodes": None,
                            "chunking_type": "automerger",
                        })
                        chunks.append({
                            "content": page["page_content"],
                            "metadata": md,
                        })

                # now push into your Datastax (or FAISS) list exactly
                self.all_doc_chunks_datastax.extend(
                    self._prepare_datastax_chunks(chunks)
                )

            logger.info(
                f"Created {len(self.all_doc_chunks_datastax)} chunks "
                f"({'chunked' if pss else 'un-chunked'})"
            )
            return self.all_doc_chunks_datastax

        except Exception as e:
            logger.error(f"Error in chunk creation: {e}")
            raise

    def _process_document(
        self,
        pages: List[Dict[str, Any]],
        filename: str
    ) -> List[Dict[str, Any]]:
        """
        Wrap into your AutoMergeChunker.
        """
        return self.auto_merger._create_chunks(pages, self.config)
