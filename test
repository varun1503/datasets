import re
import json
import unicodedata
from typing import List, Dict, Tuple
from docx import Document
from collections import OrderedDict

# ---------- helpers ----------
def norm(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()

def read_docx_lines(path: str) -> List[str]:
    doc = Document(path)
    lines: List[str] = []
    for p in doc.paragraphs:
        t = norm(p.text)
        if t:
            lines.append(t)
    for tbl in doc.tables:
        for row in tbl.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    t = norm(p.text)
                    if t:
                        lines.append(t)
    return lines

# ---------- patterns (more tolerant) ----------
REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)

# Accept: "RFR 1", "RFR1", "[RFR1]:", "[ RFR-2 ]", "RFR-3:", etc.
RFR_RX = re.compile(
    r"^\s*ÓÄÅ?\s*RFR\s*[-:]?\s*(\d+)\s*ÓÄÅ?\s*:?\s*$",
    re.IGNORECASE
)

# < ... > extractor (robust for "<...>"); we only capture inside angle brackets
BRACKETS_RX  = re.compile(r"<\s*([^>]+?)\s*>")

# Q key can appear as "Q3", "Q3:", ":<Q3", "<Q3:"; when we test parts we allow optional colons/spaces
Q_KEY_RX     = re.compile(r"^\s*:?\s*Q\d+\s*:?\s*$", re.IGNORECASE)

# Modeling Team‚Äôs/Team's Response variations
RESP_HDR_RX  = re.compile(
    r"Modeling\s+Team[‚Äô']?s\s+Response",
    re.IGNORECASE
)

# ---------- small heuristics ----------
INTERROGATIVE_START = re.compile(
    r"^\s*(what|why|how|which|when|where|who|whom|whose|does|do|did|is|are|was|were|can|could|should|would|will|please)\b",
    re.IGNORECASE
)

def is_question_like(text: str) -> bool:
    """
    Heuristic to classify the IMVP question inside <...>.
    - Prefer strings that end with '?'
    - Otherwise accept interrogative-start strings or those ending with ':'
    """
    t = (text or "").strip()
    if not t:
        return False
    if t.endswith("?"):
        return True
    if t.endswith(":"):
        return True
    if INTERROGATIVE_START.search(t):
        return True
    return False

def clean_q_key(part: str) -> str:
    """
    Normalize a Q key like 'Q3:' -> 'Q3', ': Q12 :' -> 'Q12'
    """
    t = norm(part)
    # strip leading ':' and trailing ':'
    t = re.sub(r"^\s*:\s*", "", t)
    t = re.sub(r"\s*:\s*$", "", t)
    return t

def extract_meta_from_rfr_header(line: str) -> Tuple[str, str, str]:
    """
    From an RFR header line, pull three things out of <...> groups:
      - q_key: the 'Q#' token (e.g., 'Q3')
      - section: first bracketed non-question-like part that isn't the q_key
      - imvp: last bracketed question-like part (doesn't have to end with '?')
    """
    q_key = ""
    section = ""
    imvp = ""

    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    # Identify q_key by regex; pick the first match
    for part in parts:
        if Q_KEY_RX.match(part):
            q_key = clean_q_key(part)
            break

    # Identify IMVP question: prefer the last question-like part not equal to q_key
    q_candidates = [p for p in parts if p != q_key and is_question_like(p)]
    if q_candidates:
        imvp = q_candidates[-1]

    # Section: first non-q_key part that is not question-like
    for part in parts:
        if part == q_key:
            continue
        if not is_question_like(part):
            section = part
            break

    # Fallback: if still empty, choose the shortest non-q_key non-question-like part
    if not section:
        non_q = [p for p in parts if p != q_key and not is_question_like(p)]
        if non_q:
            section = sorted(non_q, key=len)[0]

    return q_key, section, imvp

def unwrap_if_surrounded_by_brackets(text: str) -> str:
    """
    If the entire response is like '<...>', unwrap once.
    """
    m = BRACKETS_RX.fullmatch(text or "")
    return norm(m.group(1)) if m else text

def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    # Start after an explicit "Request Items" header if present
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    L = lines[start:]

    rows: List[Dict] = []
    i = 0
    while i < len(L):
        line = L[i]

        # --- RFR header found ---
        if RFR_RX.search(line):
            q_key, section, imvp_q = extract_meta_from_rfr_header(line)
            responses: List[str] = []
            i += 1

            # We will:
            # 1) Prefer "Modeling Team's Response" blocks and aggregate each block.
            # 2) ALSO capture any orphan lines (not part of a named block) until next RFR,
            #    so nothing between RFR headers is lost.
            orphan_bucket: List[str] = []

            while i < len(L) and not RFR_RX.search(L[i]):
                cur = L[i]

                if RESP_HDR_RX.search(cur):
                    # Flush any accumulated orphan lines into responses first
                    if orphan_bucket:
                        orphan_text = norm(" ".join(orphan_bucket))
                        orphan_text = unwrap_if_surrounded_by_brackets(orphan_text)
                        if orphan_text:
                            responses.append(orphan_text)
                        orphan_bucket = []

                    # Read a formal response block
                    i += 1
                    block: List[str] = []
                    while i < len(L) and not RESP_HDR_RX.search(L[i]) and not RFR_RX.search(L[i]):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    resp = unwrap_if_surrounded_by_brackets(resp)
                    if resp:
                        responses.append(resp)
                    # Do not 'continue' here; the while condition will re-check next line
                    continue

                # Not a formal response header and not a new RFR -> orphan content
                orphan_line = norm(cur)
                if orphan_line:
                    orphan_bucket.append(orphan_line)
                i += 1

            # Flush any trailing orphan lines collected for this RFR
            if orphan_bucket:
                orphan_text = norm(" ".join(orphan_bucket))
                orphan_text = unwrap_if_surrounded_by_brackets(orphan_text)
                if orphan_text:
                    responses.append(orphan_text)

            # üîí Guard: only emit if we have IMVP or any response
            if (imvp_q and imvp_q.strip()) or responses:
                rows.append({
                    "IMVP Question": imvp_q or "",
                    "Section": section or "",
                    "rfr": { (q_key or "Q?"): " ".join(responses).strip() },
                    "doctype": "rfr",
                })
            continue

        # Not an RFR header; move on
        i += 1

    return rows

def parse_docx_to_rfr_rows(path: str) -> List[Dict]:
    return parse_lines_after_request_items(read_docx_lines(path))

# ----- MERGERS -----

def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    """
    If a row has empty IMVP but has rfr content, merge that rfr into the
    most recent prior row with the SAME Section and a non-empty IMVP.
    Drop the empty-IMVP row afterward.
    """
    out: List[Dict] = []
    last_with_imvp_by_section: dict = {}
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            # empty IMVP; try to merge
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
            else:
                # skip stray rows that have no prior anchor
                pass
    return out

def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    """
    Merge rows with identical non-empty IMVP Question:
     - Combine rfr entries
     - Keep first non-empty Section
    """
    merged: "OrderedDict[str, Dict]" = OrderedDict()
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "",
                "rfr": dict(r.get("rfr") or {}),
                "doctype": "rfr",
            }
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if not merged[imvp]["Section"] and (r.get("Section") or ""):
                merged[imvp]["Section"] = r["Section"]
    return list(merged.values())

# --------- SIMPLE RUN ---------
if __name__ == "__main__":
    DOCX_PATH = "Final RFR .docx"   # <-- your file
    OUT_PATH  = "rfr_rows.jsonl"

    rows = parse_docx_to_rfr_rows(DOCX_PATH)
    # 1) fold empty-IMVP rows into previous same-section item
    rows = collapse_empty_imvp_into_previous(rows)
    # 2) merge duplicates by identical IMVP
    rows = merge_rows_by_imvp(rows)

    with open(OUT_PATH, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"Wrote {len(rows)} row(s) to {OUT_PATH}")
