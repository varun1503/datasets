import os
import json
import ast
from typing import Optional, Any, Iterable

import pandas as pd
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH


# ---------- helpers ----------
def _bold_run(p, text, size=11):
    r = p.add_run(text)
    r.bold = True
    r.font.size = Pt(size)
    return r

def _normal_run(p, text, size=11):
    r = p.add_run(text)
    r.font.size = Pt(size)
    return r

def safe_json_loads(cell: Any):
    """Pass-through for dict/list; try json/literal for strings."""
    if isinstance(cell, (dict, list)) or cell is None:
        return cell
    if not isinstance(cell, str):
        return cell
    try:
        return json.loads(cell)
    except Exception:
        pass
    try:
        return ast.literal_eval(cell)
    except Exception:
        return cell

def _add_heading(doc: Document, text: str, size=12):
    p = doc.add_paragraph()
    _bold_run(p, text, size=size)

def _add_rfr_block(doc: Document, rfr_obj: Any):
    """
    Render an RFR section from a dict like {"Q1": "answer ...", "Q2": "..."}.
    Also tolerates JSON-ish strings by parsing first.
    """
    rfr_obj = safe_json_loads(rfr_obj)
    if not rfr_obj:
        _normal_run(doc.add_paragraph(), "(No RFR provided)")
        return

    if isinstance(rfr_obj, dict):
        for k, v in rfr_obj.items():
            # Question key (bold)
            p_q = doc.add_paragraph()
            _bold_run(p_q, f"{str(k).strip()}: ", size=11)

            # Response/value
            p_a = doc.add_paragraph()
            _bold_run(p_a, "Response: ", size=11)
            _normal_run(p_a, str(v).strip())
    else:
        # Fallback dump
        _normal_run(doc.add_paragraph(), str(rfr_obj).strip())

def _as_finding_lines(x: Any):
    """
    Normalize findings to list[str]. Accepts list/ dict / string / JSON-ish.
    """
    x = safe_json_loads(x)
    if x is None:
        return []
    if isinstance(x, list):
        return [str(it).strip() for it in x if str(it).strip()]
    if isinstance(x, dict):
        return [f"{k}: {v}" for k, v in x.items() if str(v).strip()]
    if isinstance(x, str):
        s = x.strip()
        return [s] if s else []
    return [str(x).strip()]


# ---------- main ----------
def build_simple_template(
    df: pd.DataFrame,
    model: str,
    impact: str,
    scope: str = "",
    save_dir: str = "base",
    *,
    question_col: str = "text",
    sections_col: str = "sections",
    mrmg_col: Optional[str] = "mrmg_answer",
    heading_col: Optional[str] = None,   # if you have one
    rfr_col: str = "rfr",                # your dict column (already set)
    finding_col: Optional[str] = "finding",
    blank_lines_under_mtr: int = 2
) -> str:
    """
    Creates a minimal validation template per row:
      - Question i: <text>
      - Section: <sections>
      - (optional) Heading: <heading>
      - MRMG Assessment: <mrmg_answer> (if present)
      - RFR: (renders dict {"Q1": "...", ...})
      - Findings: (bulleted list if present)
      - Modelling Team Response: (space left for writing)

    Returns path to the saved .docx
    """
    # sanity
    for col in [question_col, sections_col]:
        if col not in df.columns:
            raise KeyError(f"Missing required column: {col}")

    os.makedirs(save_dir, exist_ok=True)
    out_path = os.path.join(save_dir, f"{model}_{impact}{('_' + scope) if scope else ''}.docx")

    doc = Document()

    # Title
    t = doc.add_paragraph()
    r = t.add_run("Validation Report (Template)")
    r.bold = True
    r.font.size = Pt(16)
    t.alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph()

    # Meta
    doc.add_paragraph(f"Model: {model} | Impact: {impact}{(' | Scope: ' + scope) if scope else ''}")
    doc.add_paragraph()

    # Rows
    for i, row in df.iterrows():
        # Question
        pq = doc.add_paragraph()
        _bold_run(pq, f"Question {i+1}: ", size=12)
        _normal_run(pq, str(row[question_col]).strip())

        # Section
        ps = doc.add_paragraph()
        _bold_run(ps, "Section: ")
        _normal_run(ps, str(row[sections_col]).strip())

        # Optional Heading
        if heading_col and heading_col in df.columns:
            ph = doc.add_paragraph()
            _bold_run(ph, "Heading: ")
            _normal_run(ph, str(row.get(heading_col, "")).strip())

        # MRMG Assessment (if present)
        if mrmg_col and mrmg_col in df.columns:
            pm = doc.add_paragraph()
            _bold_run(pm, "MRMG Assessment: ")
            _normal_run(pm, str(row.get(mrmg_col, "")).strip())

        # RFR
        if rfr_col in df.columns:
            _add_heading(doc, "RFR", size=12)
            _add_rfr_block(doc, row.get(rfr_col))

        # Findings
        if finding_col and finding_col in df.columns:
            _add_heading(doc, "Findings", size=12)
            lines = _as_finding_lines(row.get(finding_col))
            if lines:
                for line in lines:
                    p = doc.add_paragraph(style=None)
                    try:
                        p.style = doc.styles['List Bullet']  # bullet style if available
                    except Exception:
                        pass
                    _normal_run(p, line)
            else:
                _normal_run(doc.add_paragraph(), "(No findings provided)")

        # Modelling Team Response (space)
        pmt = doc.add_paragraph()
        _bold_run(pmt, "Modelling Team Response", size=11)
        for _ in range(max(0, blank_lines_under_mtr)):
            doc.add_paragraph()

        # spacer
        doc.add_paragraph()

    doc.save(out_path)
    return out_path
