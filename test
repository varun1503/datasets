accuracy_check.py (class only, no argparse, no run_accuracy)

pip install fuzzysearch

from future import annotations import sys, os, re from dataclasses import dataclass, field from typing import List, Optional, Dict, Iterable from fuzzysearch import find_near_matches

(Optional) Keep your original path tweak; harmless if path doesn't exist

sys.path.append(r"C:\Users\vvaishy\OneDrive - American Express\projects\Adverse-action-letter\Adverse-action-letter-review") try: from utils.foldertolist import list_file_paths as lst_paths except Exception: lst_paths = None  # fallback if the helper isn't present

@dataclass class AccuracyCheck: """ Enhanced version that mirrors per-file reporting and keyword-at-end behavior.

Import and create an instance of `AccuracyCheck`, then call `.run()` directly.
"""

max_l_dist: int = 1
credit_bureau_list: List[str] = field(default_factory=lambda: [
    "Experian",
    "D&B corporation",
    "TransUnion Consumer Relations",
    "LexisNexis Risk Solutions Bureau LLC",
])
across_page_filler: str = "Continued  on  reverse  side"
lead_sentence_1: str = "Here's the reason we made the decision"
lead_sentence_2: str = "Reason(s) for Our Decision"

# Keywords we want to surface at the end of report
keyword_hits: List[str] = field(default_factory=lambda: [
    "adequacy",
    "accurate",
])

# ----------------------------- helpers -----------------------------

@staticmethod
def _slice_next_sentences(content: str, start_idx: int, n_sentences: int) -> str:
    if start_idx < 0 or start_idx >= len(content):
        return ""
    tail = re.sub(r"[ \t]+", " ", content[start_idx:])
    parts = re.split(r"(?<=[\.!?])\s+", tail)
    return " ".join(parts[:max(1, n_sentences)]).strip()

def _get_credit_bureaus(self, content: str) -> List[str]:
    return [cb for cb in self.credit_bureau_list if cb in content]

@staticmethod
def _get_dates(content: str) -> List[str]:
    pattern = (
        r"(?:January|February|March|April|May|June|July|August|September|October|November|December)"
        r"\s+(?:[1-9]|[12]\d|3[01]),?\s+\d{4}"
    )
    return re.findall(pattern, content)

@staticmethod
def _sentences_with_keywords(content: str, keywords: Iterable[str]) -> List[str]:
    sentences = re.split(r"(?<=[\.!?])\s+", content)
    hits: List[str] = []
    for s in sentences:
        s_clean = s.strip()
        if not s_clean:
            continue
        for kw in keywords:
            if re.search(rf"\b{re.escape(kw)}\b", s_clean, flags=re.IGNORECASE):
                hits.append(s_clean)
                break
    # de-duplicate preserving order
    seen, out = set(), []
    for h in hits:
        if h not in seen:
            seen.add(h)
            out.append(h)
    return out

# ----------------------------- extractors -----------------------------

def find_fico_score(self, content: str) -> str:
    hits = find_near_matches("FICO score was", content, max_l_dist=self.max_l_dist)
    if not hits:
        return "not found"
    s = hits[0].start
    block = self._slice_next_sentences(content, s, 3)
    first_sentence = block.split(".")[0]
    return first_sentence.strip() if first_sentence else block

def find_factors(self, content: str) -> str:
    phrases = [
        "The following are the key factors that contributed to your FICO score",
        "the key factors that contributed to your FICO score",
    ]
    for phr in phrases:
        hits = find_near_matches(phr, content, max_l_dist=self.max_l_dist)
        if hits:
            s = hits[0].start
            return self._slice_next_sentences(content, s, 7)
    return "not found"

def find_creditor(self, content: str) -> str:
    hits = find_near_matches("The creditor is", content, max_l_dist=self.max_l_dist)
    if not hits:
        return "not found"
    s = hits[0].start
    return self._slice_next_sentences(content, s, 2)

def find_your_right(self, content: str) -> str:
    bureaus = self._get_credit_bureaus(content)
    if not bureaus:
        return "not found (no credit bureau detected in document)"
    hits = find_near_matches(
        "Your Right to Get Your Credit Report", content, max_l_dist=self.max_l_dist
    )
    if not hits:
        return "not found"
    s = hits[0].start
    block = self._slice_next_sentences(content, s, 10)
    if self.across_page_filler in block:
        block = self._slice_next_sentences(content, s, 17)
    return block

def find_credit_bureaus(self, content: str) -> List[str]:
    return self._get_credit_bureaus(content)

def find_5th_subfactor(self, content: str) -> str:
    hits = find_near_matches(
        "inquiries on your report in the last 12 months",
        content,
        max_l_dist=self.max_l_dist,
    )
    if not hits:
        return "not found"
    s = hits[0].start
    return self._slice_next_sentences(content, s, 2)

def find_decline_reason(self, content: str) -> str:
    hits1 = find_near_matches(self.lead_sentence_1, content, max_l_dist=self.max_l_dist)
    hits2 = find_near_matches(self.lead_sentence_2, content, max_l_dist=self.max_l_dist)
    if not hits1 and not hits2:
        return "not found"
    s = (hits1 or hits2)[0].start
    return self._slice_next_sentences(content, s, 15)

def find_first_date(self, content: str) -> str:
    dates = self._get_dates(content)
    return dates[0] if dates else "not found"

# ----------------------------- orchestrator -----------------------------

def analyze_text(self, content: str) -> Dict[str, str]:
    return {
        "First Date": self.find_first_date(content),
        "FICO Score": self.find_fico_score(content),
        "FICO Factors": self.find_factors(content),
        "Creditor": self.find_creditor(content),
        "Your Right Section": self.find_your_right(content),
        "Credit Bureaus Found": ", ".join(self.find_credit_bureaus(content)) or "none",
        "5th Subfactor (Inquiries 12mo)": self.find_5th_subfactor(content),
        "Decline Reason": self.find_decline_reason(content),
    }

def _write_report(self, input_path: str, info: Dict[str, str], output_dir: Optional[str]) -> str:
    base = os.path.basename(input_path)
    name, _ = os.path.splitext(base)
    out_dir = output_dir if output_dir else os.path.dirname(os.path.abspath(input_path))
    os.makedirs(out_dir, exist_ok=True)
    out_path = os.path.join(out_dir, f"{name}.accuracy.txt")

    lines: List[str] = [f"FILE: {input_path}"]
    for k in [
        "First Date",
        "FICO Score",
        "FICO Factors",
        "Creditor",
        "Your Right Section",
        "Credit Bureaus Found",
        "5th Subfactor (Inquiries 12mo)",
        "Decline Reason",
    ]:
        lines.append(f"{k}: {info.get(k, 'n/a')}")

    # Append keyword hits LAST ("below that")
    lines.append("-" * 96)
    lines.append("Keyword Hits (adequacy/accurate):")
    lines.append(info.get("Keyword Hits (adequacy/accurate)", "none"))
    lines.append("-" * 96)

    with open(out_path, "w", encoding="utf-8") as out:
        out.write("\n".join(lines))
    return out_path

def run(
    self,
    file_paths_txt: List[str],
    output_dir: Optional[str] = None,
    write_combined: bool = False,
    combined_report_path: Optional[str] = None,
) -> Dict[str, Dict[str, str]]:
    results: Dict[str, Dict[str, str]] = {}
    combined_lines: List[str] = []

    if write_combined and not combined_report_path:
        raise ValueError("combined_report_path is required when write_combined=True")

    if output_dir:
        os.makedirs(output_dir, exist_ok=True)

    for path in file_paths_txt:
        try:
            with open(path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
        except Exception as e:
            err = {"ERROR": f"reading file failed: {e}"}
            results[path] = err
            if write_combined:
                combined_lines.append(f"FILE: {path}\nERROR: {e}\n{'-'*96}")
            continue

        info = self.analyze_text(content)

        kw_sentences = self._sentences_with_keywords(content, self.keyword_hits)
        if kw_sentences:
            if len(kw_sentences) > 25:
                kw_sentences = kw_sentences[:25] + ["â€¦ (truncated)"]
            info["Keyword Hits (adequacy/accurate)"] = "\n".join(f"- {s}" for s in kw_sentences)
        else:
            info["Keyword Hits (adequacy/accurate)"] = "none"

        results[path] = info
        report_path = self._write_report(path, info, output_dir)

        if write_combined:
            with open(report_path, "r", encoding="utf-8") as rp:
                combined_lines.extend(rp.read().splitlines())

    if write_combined and combined_lines:
        os.makedirs(os.path.dirname(os.path.abspath(combined_report_path)), exist_ok=True)
        with open(combined_report_path, "w", encoding="utf-8") as out:
            out.write("\n".join(combined_lines))

    return results
