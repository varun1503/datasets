import spacy

# Load the English NLP model (Ensure 'en_core_web_sm' is available in your environment)
nlp = spacy.load("en_core_web_sm")

def preprocess_and_lemmatize(sentences):
    """Preprocess a list of sentences by lowercasing, removing punctuation, stripping spaces, and applying lemmatization."""
    processed = []
    
    for sentence in sentences:
        sentence = sentence.lower().strip()  # Convert to lowercase and remove extra spaces
        doc = nlp(sentence)  # Process the text with spaCy
        lemmatized_sentence = " ".join(token.lemma_ for token in doc)  # Extract lemmas
        processed.append(lemmatized_sentence)
    
    return processed

# Example usage:
sentences = ["Running quickly towards the finish line!", "This is a demonstration of lemmatization."]
print(preprocess_and_lemmatize(sentences))
