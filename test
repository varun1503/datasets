import re
import json
import unicodedata
import os
import pandas as pd
from typing import List, Dict, Tuple
from docx import Document
from collections import OrderedDict
from docx.oxml.ns import qn
from docx.table import Table
from docx.text.paragraph import Paragraph


# ---------------- HELPER UTILS ----------------

def norm(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()


def clean_greater_than(lines):
    return [re.sub(r'>.*$', '', s).strip() for s in lines]


# ------------ REGEX PATTERNS ------------------

REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)
RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)
BRACKETS_RX = re.compile(r"<\s*([^>]+?)\s*>")
Q_KEY_RX = re.compile(r"^\s*Q\d+\s*:?\s*", re.IGNORECASE)
RESP_HDR_RX = re.compile(r"Modeling Team['']?s Response", re.IGNORECASE)

TEST_TAG_RX = re.compile(r"^Test\s*(\w+)", re.IGNORECASE)


# ------------- DOCX LINE READING ----------------

def read_docx_lines(path: str) -> List[str]:
    doc = Document(path)
    lines: List[str] = []

    for child in doc.element.body.iterchildren():
        if child.tag == qn("w:p"):
            t = norm(Paragraph(child, doc).text)
            if t:
                lines.append(t)

        elif child.tag == qn("w:tbl"):
            tbl = Table(child, doc)
            for row in tbl.rows:
                row_text = []
                for cell in row.cells:
                    for p in cell.paragraphs:
                        t = norm(p.text)
                        if t:
                            row_text.append(t)
                if row_text:
                    lines.append(" | ".join(row_text))

    return lines


# ------------------------------------------------------

def extract_meta_from_rfr_header(line: str):
    """
    Extracts: IMVP question, section, q_key, test_tag, and RFR question
    """
    q_key = ""
    section = ""
    imvp = ""
    test_key = None
    rfr_question = ""

    parts = [norm(x) for x in BRACKETS_RX.findall(line)]

    # Track indices of special parts
    q_key_idx = -1
    imvp_idx = -1
    test_idx = -1

    # Detect IMVP question (one ending with ?)
    questions = [p for p in parts if p.endswith("?")]
    if questions:
        imvp = questions[-1]
        imvp_idx = parts.index(imvp) if imvp in parts else -1

    # Detect QX:
    for idx, p in enumerate(parts):
        m = Q_KEY_RX.match(p)
        if m:
            # Extract just the Q key (e.g., "Q1")
            q_key = re.sub(r':.*$', '', p).strip()
            q_key_idx = idx
            # Everything after the colon is the RFR question
            if ':' in p:
                rfr_question = p.split(':', 1)[1].strip()
            break

    # Detect Test tag
    for idx, p in enumerate(parts):
        m = TEST_TAG_RX.match(p)
        if m:
            tag_value = m.group(1).lower()
            test_key = f"tests{tag_value}"
            test_idx = idx
            break

    # Detect Section: should be the part BEFORE the Q_key
    if q_key_idx > 0:
        # Look backwards from q_key position
        for idx in range(q_key_idx - 1, -1, -1):
            p = parts[idx]
            # Skip if it's the IMVP question or test tag
            if p == imvp or idx == test_idx:
                continue
            section = p
            break

    return q_key, section, imvp, test_key, rfr_question


# ------------------------------------------------------

def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:

    # Start after "Request Items"
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break

    L = lines[start:]
    rows = []
    i = 0

    while i < len(L):
        line = L[i]

        if RFR_RX.search(line):
            q_key, section, imvp_q, test_tag, rfr_q = extract_meta_from_rfr_header(line)
            responses = []
            i += 1

            # Collect responses
            while i < len(L) and not RFR_RX.search(L[i]):
                cur = L[i]

                # Modeling Team Response block
                if RESP_HDR_RX.search(cur):
                    i += 1
                    block = []

                    while (
                        i < len(L)
                        and not RESP_HDR_RX.search(L[i])
                        and not RFR_RX.search(L[i])
                    ):
                        block.append(L[i])
                        i += 1

                    resp = norm(" ".join(block))
                    if resp:
                        responses.append(resp)
                    continue

                i += 1

            responses = clean_greater_than(responses)
            full_resp = " ".join(responses).strip()

            # Skip empty
            if not imvp_q:
                continue

            # Build row
            row = {
                test_tag: imvp_q,
                "section": section,
                "rfr": {q_key: rfr_q if rfr_q else full_resp}
            }

            rows.append(row)
            continue

        i += 1

    return rows


# ------------------------------------------------------

def convert_csv(rows, path):
    file_name = os.path.basename(path)
    df = pd.DataFrame(rows)
    df["file name"] = file_name
    df["type"] = "rfr"
    return df


# ------------------------------------------------------

if __name__ == "__main__":
    DOCX_PATH = "FinalRFRorignal.docx"
    OUT_PATH = "rfr_rows.json"

    rows = parse_lines_after_request_items(read_docx_lines(DOCX_PATH))
    df = convert_csv(rows, DOCX_PATH)

    print(df)

    with open(OUT_PATH, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"Wrote {len(rows)} row(s) to {OUT_PATH}")
