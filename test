import re
import json
import unicodedata
from typing import List, Dict, Tuple, Optional
from collections import OrderedDict

# Only needed if you want to read .docx directly
from docx import Document

# ---------- helpers ----------
def norm(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()

def read_docx_lines(path: str) -> List[str]:
    doc = Document(path)
    lines: List[str] = []
    for p in doc.paragraphs:
        t = norm(p.text)
        if t:
            lines.append(t)
    for tbl in doc.tables:
        for row in tbl.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    t = norm(p.text)
                    if t:
                        lines.append(t)
    return lines

# ---------- patterns (tolerant) ----------
REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)

# Accept: "RFR 1", "RFR1", "[RFR1]:", "RFR-3:", etc. (capture the number)
RFR_RX_LINE = re.compile(r"^\s*ÓÄÅ?\s*RFR\s*[-:]?\s*(\d+)\s*ÓÄÅ?\s*:?\s*$", re.IGNORECASE)

# Full-line ‚Äústarts with RFR‚Äù fallback detector
RFR_START_RX = re.compile(r"^\s*ÓÄÅ?\s*RFR\b", re.IGNORECASE)

# < ... > extractor for bracket groups
BRACKETS_RX  = re.compile(r"<\s*([^>]+?)\s*>")

# ‚ÄúQ#: ‚Ä¶‚Äù detector (for the first bracket)
Q_FIRST_BRACKET_RX = re.compile(r"^\s*Q(\d+)\s*:\s*(.+)$", re.IGNORECASE)

# Response section header
RESP_HDR_RX  = re.compile(r"Modeling\s+Team[‚Äô']?s\s+Response", re.IGNORECASE)

# Heuristic for question-like text
INTERROGATIVE_START = re.compile(
    r"^\s*(what|why|how|which|when|where|who|whom|whose|does|do|did|is|are|was|were|can|could|should|would|will|please)\b",
    re.IGNORECASE
)

def is_question_like(text: str) -> bool:
    t = (text or "").strip()
    if not t:
        return False
    return t.endswith("?") or t.endswith(":") or bool(INTERROGATIVE_START.search(t))

def unwrap_if_surrounded_by_brackets(text: str) -> str:
    m = BRACKETS_RX.fullmatch(text or "")
    return norm(m.group(1)) if m else text

# ---------- header parser (POSITIONAL) ----------
def extract_meta_from_rfr_header(line: str) -> Tuple[str, str, str, str, str]:
    """
    Positional parsing of RFR header bracket groups:
      [RFRn]: <Q# : RFR question ...> | <Section> | <IMVP question ...?>
    Returns:
      rfr_id   -> "RFR<n>" if found, else ""
      q_key    -> "Q<n>"   if found in the 1st bracket, else ""
      section  -> 2nd bracket (e.g., "Data Validation"), else fallback ""
      imvp     -> 3rd bracket (question-like), else fallback ""
      rfr_question -> FULL first bracket text including 'Q#: ...' (used as rfr dict key)
    """
    rfr_id = ""
    m = RFR_RX_LINE.search(line)
    if m:
        rfr_id = f"RFR{m.group(1)}"

    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    q_key = ""
    rfr_question = ""
    section = ""
    imvp = ""

    # Find the RFR question bracket (1st that matches "Q#: ...")
    rfr_idx = None
    for idx, p in enumerate(parts):
        m_q = Q_FIRST_BRACKET_RX.match(p)
        if m_q:
            q_key = f"Q{m_q.group(1)}"
            rfr_question = norm(p)  # keep full "Q#: ..."
            rfr_idx = idx
            break

    # Section = next bracket (positionally)
    if rfr_idx is not None and rfr_idx + 1 < len(parts):
        section = parts[rfr_idx + 1]

    # IMVP = following bracket (positionally)
    if rfr_idx is not None and rfr_idx + 2 < len(parts):
        imvp = parts[rfr_idx + 2]

    # Fallbacks if document deviates
    if not section:
        for p in parts:
            if re.search(r"\b(Data|Model|Govern|Develop|Validation|Testing|Documentation)\b", p, re.IGNORECASE):
                section = p
                break
    if not imvp:
        for p in parts:
            if p != rfr_question and p != section and is_question_like(p):
                imvp = p
                break

    return rfr_id, q_key, section, imvp, rfr_question

# ---------- core parser (works on an existing list of lines) ----------
def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    # Start after "Request Items" if present
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    L = [norm(x) for x in lines[start:] if norm(x)]

    rows: List[Dict] = []
    i = 0
    while i < len(L):
        line = L[i]

        # Is this an RFR header?
        if RFR_RX_LINE.search(line) or RFR_START_RX.search(line):
            rfr_id, q_key, section, imvp_q, rfr_question = extract_meta_from_rfr_header(line)
            responses: List[str] = []
            i += 1

            # Prefer formal response blocks, but ALSO capture any orphan lines
            orphan_bucket: List[str] = []

            while i < len(L) and not (RFR_RX_LINE.search(L[i]) or RFR_START_RX.search(L[i])):
                cur = L[i]

                if RESP_HDR_RX.search(cur):
                    # Flush orphan lines first
                    if orphan_bucket:
                        orphan_text = norm(" ".join(orphan_bucket))
                        orphan_text = unwrap_if_surrounded_by_brackets(orphan_text)
                        if orphan_text:
                            responses.append(orphan_text)
                        orphan_bucket = []

                    # Read the named "Modeling Team‚Äôs Response" block
                    i += 1
                    block: List[str] = []
                    while i < len(L) and not RESP_HDR_RX.search(L[i]) and not (RFR_RX_LINE.search(L[i]) or RFR_START_RX.search(L[i])):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    resp = unwrap_if_surrounded_by_brackets(resp)
                    if resp:
                        responses.append(resp)
                    continue

                # Orphan line (belongs to current RFR)
                orphan_line = norm(cur)
                if orphan_line:
                    orphan_bucket.append(orphan_line)
                i += 1

            # Flush trailing orphans
            if orphan_bucket:
                orphan_text = norm(" ".join(orphan_bucket))
                orphan_text = unwrap_if_surrounded_by_brackets(orphan_text)
                if orphan_text:
                    responses.append(orphan_text)

            # Only emit if we have IMVP or any response
            if (imvp_q and imvp_q.strip()) or responses:
                rows.append({
                    "IMVP Question": imvp_q or "",
                    "Section": section or "",
                    "rfr": { (rfr_question or q_key or "Q?"): " ".join(responses).strip() },
                    "doctype": "rfr",
                    "Q_key": q_key or "",
                    "rfr_id": rfr_id or "",
                })
            continue

        i += 1

    return rows

# ---------- optional mergers ----------
def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    """
    If a row has empty IMVP but has rfr content, merge that rfr into the
    most recent prior row with the SAME Section and a non-empty IMVP.
    """
    out: List[Dict] = []
    last_with_imvp_by_section: dict = {}
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
            # else: drop stray rows
    return out

def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    """Merge rows with identical non-empty IMVP; combine rfr maps, keep first non-empty Section."""
    merged: "OrderedDict[str, Dict]" = OrderedDict()
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "",
                "rfr": dict(r.get("rfr") or {}),
                "doctype": "rfr",
                "Q_key": r.get("Q_key", ""),
                "rfr_id": r.get("rfr_id", ""),
            }
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if not merged[imvp]["Section"] and (r.get("Section") or ""):
                merged[imvp]["Section"] = r["Section"]
            # keep first non-empty Q_key/rfr_id (optional: could collect lists)
            if not merged[imvp]["Q_key"] and r.get("Q_key"):
                merged[imvp]["Q_key"] = r["Q_key"]
            if not merged[imvp]["rfr_id"] and r.get("rfr_id"):
                merged[imvp]["rfr_id"] = r["rfr_id"]
    return list(merged.values())

# ---------- convenient public API ----------
def parse_rfr(
    *, 
    docx_path: Optional[str] = None, 
    lines: Optional[List[str]] = None,
    do_merge: bool = True,
    collapse_empty: bool = True,
) -> List[Dict]:
    """
    Parse RFR rows from either `docx_path` or pre-read `lines`.
    - `collapse_empty`: merge orphan rows with empty IMVP into the previous row in the same Section.
    - `do_merge`: merge rows with identical IMVP Question (combines rfr maps).
    """
    if lines is None:
        if not docx_path:
            raise ValueError("Provide either `lines` or `docx_path`.")
        lines = read_docx_lines(docx_path)

    rows = parse_lines_after_request_items(lines)
    if collapse_empty:
        rows = collapse_empty_imvp_into_previous(rows)
    if do_merge:
        rows = merge_rows_by_imvp(rows)
    return rows

# ---------- (optional) flatten helper for tabular export ----------
def flatten_rows(rows: List[Dict]) -> List[Dict]:
    """
    Expand each row's 'rfr' dict into multiple flat rows:
    Columns: rfr_id, Q_key, Section, IMVP Question, Question, Response
    """
    flat: List[Dict] = []
    for r in rows:
        section = r.get("Section", "")
        imvp = r.get("IMVP Question", "")
        q_key = r.get("Q_key", "")
        rfr_id = r.get("rfr_id", "")
        rfr_map = r.get("rfr") or {}
        for question, response in rfr_map.items():
            flat.append({
                "rfr_id": rfr_id,
                "Q_key": q_key,
                "Section": section,
                "IMVP Question": imvp,
                "Question": question,     # full "Q#: ‚Ä¶" text
                "Response": response,     # Modeling Team‚Äôs Response (combined)
            })
    return flat

# --------- example usage (comment out in library use) ---------
if __name__ == "__main__":
    # Example A: if you already have the list of lines from read_docx_lines
    # lines_list = [...]
    # rows = parse_rfr(lines=lines_list)

    # Example B: parse directly from a .docx
    # rows = parse_rfr(docx_path="Final RFR .docx")

    # Save JSONL
    # with open("rfr_rows.jsonl", "w", encoding="utf-8") as f:
    #     for r in rows:
    #         f.write(json.dumps(r, ensure_ascii=False) + "\n")

    # Optional: save flattened CSV-like JSON
    # flat = flatten_rows(rows)
    # with open("rfr_rows_flat.json", "w", encoding="utf-8") as f:
    #     json.dump(flat, f, ensure_ascii=False, indent=2)
    pass            continue
        if not is_question_like(part):
            section = part
            break

    # Fallback: if still empty, choose the shortest non-q_key non-question-like part
    if not section:
        non_q = [p for p in parts if p != q_key and not is_question_like(p)]
        if non_q:
            section = sorted(non_q, key=len)[0]

    return q_key, section, imvp

def unwrap_if_surrounded_by_brackets(text: str) -> str:
    """
    If the entire response is like '<...>', unwrap once.
    """
    m = BRACKETS_RX.fullmatch(text or "")
    return norm(m.group(1)) if m else text

def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    # Start after an explicit "Request Items" header if present
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    L = lines[start:]

    rows: List[Dict] = []
    i = 0
    while i < len(L):
        line = L[i]

        # --- RFR header found ---
        if RFR_RX.search(line):
            q_key, section, imvp_q = extract_meta_from_rfr_header(line)
            responses: List[str] = []
            i += 1

            # We will:
            # 1) Prefer "Modeling Team's Response" blocks and aggregate each block.
            # 2) ALSO capture any orphan lines (not part of a named block) until next RFR,
            #    so nothing between RFR headers is lost.
            orphan_bucket: List[str] = []

            while i < len(L) and not RFR_RX.search(L[i]):
                cur = L[i]

                if RESP_HDR_RX.search(cur):
                    # Flush any accumulated orphan lines into responses first
                    if orphan_bucket:
                        orphan_text = norm(" ".join(orphan_bucket))
                        orphan_text = unwrap_if_surrounded_by_brackets(orphan_text)
                        if orphan_text:
                            responses.append(orphan_text)
                        orphan_bucket = []

                    # Read a formal response block
                    i += 1
                    block: List[str] = []
                    while i < len(L) and not RESP_HDR_RX.search(L[i]) and not RFR_RX.search(L[i]):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    resp = unwrap_if_surrounded_by_brackets(resp)
                    if resp:
                        responses.append(resp)
                    # Do not 'continue' here; the while condition will re-check next line
                    continue

                # Not a formal response header and not a new RFR -> orphan content
                orphan_line = norm(cur)
                if orphan_line:
                    orphan_bucket.append(orphan_line)
                i += 1

            # Flush any trailing orphan lines collected for this RFR
            if orphan_bucket:
                orphan_text = norm(" ".join(orphan_bucket))
                orphan_text = unwrap_if_surrounded_by_brackets(orphan_text)
                if orphan_text:
                    responses.append(orphan_text)

            # üîí Guard: only emit if we have IMVP or any response
            if (imvp_q and imvp_q.strip()) or responses:
                rows.append({
                    "IMVP Question": imvp_q or "",
                    "Section": section or "",
                    "rfr": { (q_key or "Q?"): " ".join(responses).strip() },
                    "doctype": "rfr",
                })
            continue

        # Not an RFR header; move on
        i += 1

    return rows

def parse_docx_to_rfr_rows(path: str) -> List[Dict]:
    return parse_lines_after_request_items(read_docx_lines(path))

# ----- MERGERS -----

def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    """
    If a row has empty IMVP but has rfr content, merge that rfr into the
    most recent prior row with the SAME Section and a non-empty IMVP.
    Drop the empty-IMVP row afterward.
    """
    out: List[Dict] = []
    last_with_imvp_by_section: dict = {}
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            # empty IMVP; try to merge
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
            else:
                # skip stray rows that have no prior anchor
                pass
    return out

def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    """
    Merge rows with identical non-empty IMVP Question:
     - Combine rfr entries
     - Keep first non-empty Section
    """
    merged: "OrderedDict[str, Dict]" = OrderedDict()
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "",
                "rfr": dict(r.get("rfr") or {}),
                "doctype": "rfr",
            }
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if not merged[imvp]["Section"] and (r.get("Section") or ""):
                merged[imvp]["Section"] = r["Section"]
    return list(merged.values())

# --------- SIMPLE RUN ---------
if __name__ == "__main__":
    DOCX_PATH = "Final RFR .docx"   # <-- your file
    OUT_PATH  = "rfr_rows.jsonl"

    rows = parse_docx_to_rfr_rows(DOCX_PATH)
    # 1) fold empty-IMVP rows into previous same-section item
    rows = collapse_empty_imvp_into_previous(rows)
    # 2) merge duplicates by identical IMVP
    rows = merge_rows_by_imvp(rows)

    with open(OUT_PATH, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"Wrote {len(rows)} row(s) to {OUT_PATH}")
