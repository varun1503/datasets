from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
from cassandra.query import BatchStatement
from tqdm import tqdm
from datetime import datetime, timezone
import uuid

class CassandraBatchIngestor:
    def __init__(self, keyspace, table, cluster_nodes, username, password):
        self.keyspace = keyspace
        self.table = table
        self.cluster_nodes = cluster_nodes
        self.username = username
        self.password = password
        self._connect()

    def _connect(self):
        auth_provider = PlainTextAuthProvider(username=self.username, password=self.password)
        self.cluster = Cluster(self.cluster_nodes, auth_provider=auth_provider)
        self.session = self.cluster.connect(self.keyspace)
        self.insert_query = self.session.prepare(f"""
            INSERT INTO {self.table} (
                file_name,
                row_id,
                chunk_text,
                created_ts,
                metadata,
                use_case_id,
                use_case_name,
                embedding
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """)

    def insert_data_batch(self, chunk_data, use_case_id=101, use_case_name="Earnings Call Analysis", batch_size=50):
        batch = BatchStatement()
        for i, data_point in enumerate(tqdm(chunk_data, desc="Inserting data to Cassandra")):
            metadata = data_point.get("metadata", {})
            meta_data = {
                "parent_node": [metadata.get("parent_node")] if metadata.get("parent_node") else ["NA"],
                "doc_id": [metadata.get("doc_id")],
                "prev_node": [metadata.get("prev_node")] if metadata.get("prev_node") else ["NA"],
                "child_nodes": metadata.get("child_nodes") if metadata.get("child_nodes") else ["NA"],
                "next_node": [metadata.get("next_node")] if metadata.get("next_node") else ["NA"],
                "period": [metadata.get("period")],
                "type": [metadata.get("type")],
                "chunking_type": [metadata.get("chunking_type")],
                "company_name": [metadata.get("company_name")],
                "source_content": metadata.get("source_content")
            }

            row_id = str(uuid.uuid4())
            chunk_text = data_point["content"]
            embedding = data_point["embedding"][0]
            file_name = metadata.get("source", "unknown")
            created_ts = datetime.now(timezone.utc)

            batch.add(self.insert_query, (
                file_name,
                row_id,
                chunk_text,
                created_ts,
                meta_data,
                use_case_id,
                use_case_name,
                embedding
            ))

            if (i + 1) % batch_size == 0 or i == len(chunk_data) - 1:
                try:
                    self.session.execute(batch)
                    batch.clear()
                except Exception as e:
                    print(f"Batch insert error at index {i}: {e}")

    def close(self):
        self.cluster.shutdown()
