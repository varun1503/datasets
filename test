# accuracy_check.py (run function same as adequacy)
# pip install fuzzysearch
from __future__ import annotations
import sys, os, re
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Iterable
from fuzzysearch import find_near_matches

sys.path.append(r"C:\Users\vvaishy\OneDrive - American Express\projects\Adverse-action-letter\Adverse-action-letter-review")
try:
    from utils.foldertolist import list_file_paths
except Exception:
    def list_file_paths(folder_path: str) -> List[str]:
        acc = []
        for root, _, files in os.walk(folder_path):
            for f in files:
                if f.lower().endswith('.txt'):
                    acc.append(os.path.abspath(os.path.join(root, f)))
        return acc


@dataclass
class AccuracyCheck:
    max_l_dist: int = 1
    credit_bureau_list: List[str] = field(default_factory=lambda: [
        "Experian",
        "D&B corporation",
        "TransUnion Consumer Relations",
        "LexisNexis Risk Solutions Bureau LLC",
    ])
    across_page_filler: str = "Continued  on  reverse  side"
    lead_sentence_1: str = "Here's the reason we made the decision"
    lead_sentence_2: str = "Reason(s) for Our Decision"
    keyword_hits: List[str] = field(default_factory=lambda: ["adequacy", "accurate"])

    # ----------------- helpers -----------------

    @staticmethod
    def _slice_next_sentences(content: str, start_idx: int, n_sentences: int) -> str:
        if start_idx < 0 or start_idx >= len(content):
            return ""
        tail = re.sub(r"[ \t]+", " ", content[start_idx:])
        parts = re.split(r"(?<=[\.!?])\s+", tail)
        return " ".join(parts[:max(1, n_sentences)]).strip()

    def _get_credit_bureaus(self, content: str) -> List[str]:
        return [cb for cb in self.credit_bureau_list if cb in content]

    @staticmethod
    def _get_dates(content: str) -> List[str]:
        pattern = (
            r"(?:January|February|March|April|May|June|July|August|September|October|November|December)"
            r"\s+(?:[1-9]|[12]\d|3[01]),?\s+\d{4}"
        )
        return re.findall(pattern, content)

    @staticmethod
    def _sentences_with_keywords(content: str, keywords: Iterable[str]) -> List[str]:
        sentences = re.split(r"(?<=[\.!?])\s+", content)
        hits: List[str] = []
        for s in sentences:
            s_clean = s.strip()
            if not s_clean:
                continue
            for kw in keywords:
                if re.search(rf"\b{re.escape(kw)}\b", s_clean, flags=re.IGNORECASE):
                    hits.append(s_clean)
                    break
        seen, out = set(), []
        for h in hits:
            if h not in seen:
                seen.add(h)
                out.append(h)
        return out

    # ----------------- extractors -----------------

    def find_fico_score(self, content: str) -> str:
        hits = find_near_matches("FICO score was", content, max_l_dist=self.max_l_dist)
        if not hits:
            return "not found"
        s = hits[0].start
        block = self._slice_next_sentences(content, s, 3)
        first_sentence = block.split(".")[0]
        return first_sentence.strip() if first_sentence else block

    def find_factors(self, content: str) -> str:
        phrases = [
            "The following are the key factors that contributed to your FICO score",
            "the key factors that contributed to your FICO score",
        ]
        for phr in phrases:
            hits = find_near_matches(phr, content, max_l_dist=self.max_l_dist)
            if hits:
                s = hits[0].start
                return self._slice_next_sentences(content, s, 7)
        return "not found"

    def find_creditor(self, content: str) -> str:
        hits = find_near_matches("The creditor is", content, max_l_dist=self.max_l_dist)
        if not hits:
            return "not found"
        s = hits[0].start
        return self._slice_next_sentences(content, s, 2)

    def find_your_right(self, content: str) -> str:
        bureaus = self._get_credit_bureaus(content)
        if not bureaus:
            return "not found (no credit bureau detected in document)"
        hits = find_near_matches(
            "Your Right to Get Your Credit Report", content, max_l_dist=self.max_l_dist
        )
        if not hits:
            return "not found"
        s = hits[0].start
        block = self._slice_next_sentences(content, s, 10)
        if self.across_page_filler in block:
            block = self._slice_next_sentences(content, s, 17)
        return block

    def find_credit_bureaus(self, content: str) -> List[str]:
        return self._get_credit_bureaus(content)

    def find_5th_subfactor(self, content: str) -> str:
        hits = find_near_matches(
            "inquiries on your report in the last 12 months",
            content,
            max_l_dist=self.max_l_dist,
        )
        if not hits:
            return "not found"
        s = hits[0].start
        return self._slice_next_sentences(content, s, 2)

    def find_decline_reason(self, content: str) -> str:
        hits1 = find_near_matches(self.lead_sentence_1, content, max_l_dist=self.max_l_dist)
        hits2 = find_near_matches(self.lead_sentence_2, content, max_l_dist=self.max_l_dist)
        if not hits1 and not hits2:
            return "not found"
        s = (hits1 or hits2)[0].start
        return self._slice_next_sentences(content, s, 15)

    def find_first_date(self, content: str) -> str:
        dates = self._get_dates(content)
        return dates[0] if dates else "not found"

    # ----------------- orchestrator -----------------

    def analyze_text(self, content: str) -> Dict[str, str]:
        return {
            "First Date": self.find_first_date(content),
            "FICO Score": self.find_fico_score(content),
            "FICO Factors": self.find_factors(content),
            "Creditor": self.find_creditor(content),
            "Your Right Section": self.find_your_right(content),
            "Credit Bureaus Found": ", ".join(self.find_credit_bureaus(content)) or "none",
            "5th Subfactor (Inquiries 12mo)": self.find_5th_subfactor(content),
            "Decline Reason": self.find_decline_reason(content),
        }

    def run(self, input_folder: str, output_folder: str) -> Dict[str, Dict[str, str]]:
        os.makedirs(output_folder, exist_ok=True)
        files = list_file_paths(input_folder)
        results: Dict[str, Dict[str, str]] = {}

        for path in files:
            try:
                with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
            except Exception as e:
                results[path] = {"ERROR": str(e)}
                continue

            info = self.analyze_text(content)

            kw_sentences = self._sentences_with_keywords(content, self.keyword_hits)
            if kw_sentences:
                if len(kw_sentences) > 25:
                    kw_sentences = kw_sentences[:25] + ['… (truncated)']
                info['Keyword Hits (adequacy/accurate)'] = "\n".join(f"- {s}" for s in kw_sentences)
            else:
                info['Keyword Hits (adequacy/accurate)'] = 'none'

            base = os.path.basename(path)
            name, _ = os.path.splitext(base)
            out_path = os.path.join(output_folder, f"{name}.accuracy.txt")

            with open(out_path, 'w', encoding='utf-8') as out:
                for k, v in info.items():
                    out.write(f"{k}: {v}\n")
                out.write('-'*96 + '\n')

            results[path] = info

        return results


Done — the script now matches the adequacy-style run() function signature:

checker = AccuracyCheck()
checker.run(input_folder=r"C:\letters", output_folder=r"C:\reports")

✅ It automatically reads all .txt files in the input folder, analyzes them,
and writes each <name>.accuracy.txt file to the output folder.
