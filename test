# =========================================================
# JUPYTER NOTEBOOK â€“ FINAL CORRECT BaseChatClient IMPLEMENTATION
# =========================================================

import asyncio
from typing import Sequence, Any, MutableMapping, Callable, AsyncIterable

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompt_values import ChatPromptValue

from agent_framework import ChatAgent
from agent_framework.clients import BaseChatClient
from agent_framework.messages import ChatMessage, Role, TextContent
from agent_framework.responses import ChatResponse
from agent_framework.types import ToolProtocol


# =========================================================
# SAFE TEXT EXTRACTION (VERSION AGNOSTIC)
# =========================================================
def extract_text_from_message(m: ChatMessage) -> str:
    if hasattr(m, "content") and m.content:
        return extract_text_from_content(m.content)
    if hasattr(m, "contents") and m.contents:
        return extract_text_from_content(m.contents[0])
    return ""

def extract_text_from_content(c) -> str:
    if hasattr(c, "value"):
        return c.value
    if hasattr(c, "text"):
        return c.text
    if hasattr(c, "data"):
        return c.data
    return ""


# =========================================================
# ORG STANDARD MODEL FACTORY
# =========================================================
def model(version: str):
    return MyCustomLLM(version)


# =========================================================
# CUSTOM LLM (ChatPromptValue ONLY)
# =========================================================
class MyCustomLLM:
    def __init__(self, version: str):
        self.version = version

    def invoke(self, prompt_value: ChatPromptValue) -> ChatMessage:
        print(f"\nðŸ”µ LLM model({self.version}) INVOKED\n")
        print(prompt_value.to_string())

        return ChatMessage(
            role=Role.ASSISTANT,
            contents=[
                TextContent(text="Hello ðŸ‘‹ This response came from model('3')")
            ],
        )


# =========================================================
# OFFICIAL BaseChatClient IMPLEMENTATION (FIX)
# =========================================================
class MyChatClient(BaseChatClient):

    async def _inner_get_response(
        self,
        messages: Sequence[ChatMessage],
        *,
        tools: Sequence[ToolProtocol] | None = None,
        tool_choice: Callable[..., Any] | None = None,
        chat_options: MutableMapping[str, Any] | None = None,
        **kwargs: Any,
    ) -> ChatResponse:

        # 1ï¸âƒ£ Convert messages â†’ prompt
        prompt_template = ChatPromptTemplate.from_messages(
            [(m.role, extract_text_from_message(m)) for m in messages]
        )

        prompt_value = prompt_template.format_prompt()

        # 2ï¸âƒ£ ORG STANDARD MODEL CALL
        llm = model("3")
        assistant_message = llm.invoke(prompt_value)

        # 3ï¸âƒ£ MUST wrap in ChatResponse
        return ChatResponse(message=assistant_message)

    async def _inner_get_streaming_response(
        self,
        messages: Sequence[ChatMessage],
        *,
        tools: Sequence[ToolProtocol] | None = None,
        tool_choice: Callable[..., Any] | None = None,
        chat_options: MutableMapping[str, Any] | None = None,
        **kwargs: Any,
    ) -> AsyncIterable[ChatResponse]:
        # Streaming not supported yet
        raise NotImplementedError("Streaming not implemented")


# =========================================================
# GREETING AGENT
# =========================================================
class GreetingAgent(ChatAgent):
    def __init__(self):
        super().__init__(
            name="GreetingAgent",
            chat_client=MyChatClient(),
            instructions="You are a friendly greeting assistant.",
        )


# =========================================================
# RUN
# =========================================================
async def main():
    agent = GreetingAgent()
    response = await agent.run("Hi")

    print("\nðŸŸ¢ FINAL RESPONSE TEXT:\n")
    print(extract_text_from_message(response.messages[0]))

await main()# =========================================================
# RUN
# =========================================================
async def main():
    agent = GreetingAgent()
    response = await agent.run("Hi")

    print("\nðŸŸ¢ FINAL RESPONSE TEXT:\n")
    print(extract_text_from_message(response.messages[0]))

await main()
