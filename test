from docx import Document
from docx.text.paragraph import Paragraph
from docx.oxml import OxmlElement
import re, json, ast
import pandas as pd


# ------------------------ helpers ------------------------
def _norm(s): return re.sub(r"\s+", " ", (s or "")).strip().lower()

def _insert_before(p: Paragraph, text=""):
    new_p = OxmlElement("w:p"); p._p.addprevious(new_p)
    q = Paragraph(new_p, p._parent)
    if text: q.add_run(text)
    return q

def _insert_after(p: Paragraph, text=""):
    new_p = OxmlElement("w:p"); p._p.addnext(new_p)
    q = Paragraph(new_p, p._parent)
    if text: q.add_run(text)
    return q

def _delete_range(paragraphs, i_from, i_to):
    if i_from is None or i_to is None or i_from > i_to: return
    for k in range(i_to, i_from-1, -1):
        elm = paragraphs[k]._element
        elm.getparent().remove(elm)

def _safe_dict(x):
    if isinstance(x, dict): return x
    if isinstance(x, str):
        s = x.strip()
        if not s: return {}
        try: return json.loads(s)
        except Exception:
            try: return ast.literal_eval(s)
            except Exception: return {}
    return {}

def _snum(text):
    m = re.search(r"\bS\s*(\d+)\b", text or "", flags=re.IGNORECASE)
    return f"S{m.group(1)}" if m else ""

def _looks_like_test(p):
    return bool(re.search(r"\btest\b", _norm(p.text)))


# -------------------- main unified function --------------------
def update_doc_with_findings_and_tags(
    doc_path: str,
    findings_df: pd.DataFrame,
    tags_df: pd.DataFrame,
    output_path: str,
    finding_col: str = "Finding Details",
    rfr_col: str = "rfr_value",
    mrmg_col: str = "MRMG_Assessment",
    tag_col: str = "text",
    end_heading_text: str = "Validation Assessment Details",
    mtr_heading_base: str = "Modelling Team Response",
):
    """
    Performs both:
      1) Updates global 'Finding Details' section.
      2) Updates all per-tag (S1/S2) sections.
    """

    doc = Document(doc_path)
    paragraphs = doc.paragraphs

    # ---------- 1️⃣ Update Finding Details section ----------
    start_idx = next((i for i, p in enumerate(paragraphs) if "finding details" in _norm(p.text)), None)
    if start_idx is None:
        raise ValueError("Could not find 'Finding Details' section.")

    end_idx = next((j for j in range(start_idx + 1, len(paragraphs))
                    if _norm(end_heading_text) in _norm(paragraphs[j].text)), None)
    if end_idx is None:
        end_idx = len(paragraphs)

    # remove between headings but keep them
    for k in range(end_idx - 1, start_idx, -1):
        elm = paragraphs[k]._element
        elm.getparent().remove(elm)

    anchor_before = paragraphs[start_idx + 1] if (start_idx + 1) < len(paragraphs) else None
    insert_fn = lambda txt: _insert_before(anchor_before, txt) if anchor_before else _insert_after(paragraphs[start_idx], txt)

    m_counter = 1
    for _, row in findings_df.iterrows():
        finding_text = str(row.get(finding_col, "") or "").strip()
        rfr_dict = _safe_dict(row.get(rfr_col, {}))
        mrmg_text = str(row.get(mrmg_col, "") or "").strip()

        # Finding
        p = insert_fn(f"Finding M{m_counter}")
        if p.runs: p.runs[0].bold = True
        insert_fn(finding_text)

        # RFR pairs
        items = list(rfr_dict.items()) or [( "", "" )]
        for q, resp in items:
            p = insert_fn(f"Challenge M{m_counter}")
            if p.runs: p.runs[0].bold = True
            insert_fn(str(q).strip())

            p = insert_fn(f"Modeling Team Response M{m_counter}")
            if p.runs: p.runs[0].bold = True
            insert_fn(str(resp).strip())

        # MRMG Assessment
        p = insert_fn(f"MRMG Assessment M{m_counter}")
        if p.runs: p.runs[0].bold = True
        insert_fn(mrmg_text)

        insert_fn("")  # spacer
        m_counter += 1

    # ---------- 2️⃣ Update each tag section (S1/S2) ----------
    for _, row in tags_df.iterrows():
        tag = str(row.get(tag_col, "") or "").strip()
        rfr = _safe_dict(row.get(rfr_col, {}))
        mrmg = str(row.get(mrmg_col, "") or "").strip()
        if not tag:
            continue

        sn = _snum(tag)
        paras = doc.paragraphs
        tag_norm = _norm(tag)

        start_idx = next((i for i, p in enumerate(paras) if tag_norm in _norm(p.text)), None)
        if start_idx is None and sn:
            start_idx = next((i for i, p in enumerate(paras) if sn.lower() in _norm(p.text)), None)
        if start_idx is None:
            continue

        next_test = None
        for j in range(start_idx + 1, len(paras)):
            if _looks_like_test(paras[j]):
                next_test = j
                break
        section_end = next_test if next_test is not None else len(paras)

        mtr_idx, eval_idx = None, None
        for j in range(start_idx + 1, section_end):
            t = _norm(paras[j].text)
            if mtr_idx is None and ("modelling team response" in t or "modeling team response" in t):
                mtr_idx = j
            if eval_idx is None and "mrmg evaluation" in t:
                eval_idx = j
            if mtr_idx is not None and eval_idx is not None:
                break

        if eval_idx is not None:
            anchor_before = paras[eval_idx]
        elif mtr_idx is not None:
            anchor_before = _insert_after(paras[mtr_idx])
        else:
            base = paras[section_end - 1] if section_end > start_idx + 1 else paras[start_idx]
            anchor_before = _insert_after(base)

        # clear old Challenge/MTR/MRMG Assessment for that S#
        scan_from = mtr_idx if mtr_idx is not None else start_idx
        scan_to = (eval_idx - 1) if eval_idx is not None else (section_end - 1)
        kill = []
        i = scan_from + 1
        while i <= scan_to and i < len(doc.paragraphs):
            t = _norm(doc.paragraphs[i].text)
            if (t.startswith(f"challenge {sn.lower()}") or
                t.startswith(f"{_norm(mtr_heading_base)} {sn.lower()}") or
                t.startswith(f"modeling team response {sn.lower()}") or
                t.startswith(f"mrmg assessment {sn.lower()}")):
                start_del = i
                end_del = min(i + 1, len(doc.paragraphs) - 1)
                kill.append((start_del, end_del))
                i = end_del + 1
                continue
            i += 1
        for a, b in reversed(kill):
            _delete_range(doc.paragraphs, a, b)

        paras = doc.paragraphs
        try:
            _ = anchor_before._p
        except Exception:
            anchor_before = paras[min(eval_idx, len(paras) - 1)] if eval_idx is not None else paras[-1]

        # Insert RFR + MRMG Assessment
        if rfr:
            for ch_text, resp_text in rfr.items():
                ch_head = f"Challenge {sn}" if sn else "Challenge"
                mtr_head = f"{mtr_heading_base} {sn}" if sn else mtr_heading_base

                p = _insert_before(anchor_before, ch_head)
                if p.runs: p.runs[0].bold = True
                _insert_before(anchor_before, str(ch_text or "").strip())

                p = _insert_before(anchor_before, mtr_head)
                if p.runs: p.runs[0].bold = True
                _insert_before(anchor_before, str(resp_text or "").strip())

                _insert_before(anchor_before, "")

        if mrmg:
            a_head = f"MRMG Assessment {sn}" if sn else "MRMG Assessment"
            p = _insert_before(anchor_before, a_head)
            if p.runs: p.runs[0].bold = True
            _insert_before(anchor_before, mrmg)
            _insert_before(anchor_before, "")

    doc.save(output_path)
    print(f"✅ Final merged update saved to: {output_path}")
update_doc_with_findings_and_tags(
    doc_path="input.docx",
    findings_df=findings_df,  # global "Finding Details" table
    tags_df=tags_df,          # per-tag S1/S2 data
    output_path="final.docx",
    finding_col="Finding Details",
    rfr_col="rfr_value",
    mrmg_col="MRMG_Assessment",
    tag_col="text",
    mtr_heading_base="Modelling Team Response"
)
