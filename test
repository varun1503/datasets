# =========================================================
# JUPYTER NOTEBOOK â€“ SINGLE CELL (FULL WORKING EXAMPLE)
# =========================================================

import asyncio
from typing import Any
from datetime import datetime

# -------------------------
# agent-framework imports
# -------------------------
from agent_framework import BaseAgent, AgentRunResponse, AgentThread
from agent_framework.messages import ChatMessage, Role

# -------------------------
# LangChain prompt (org standard)
# -------------------------
from langchain_core.prompts import ChatPromptTemplate


# =========================================================
# TOOL
# =========================================================
def get_time_of_day() -> str:
    """
    Returns the current time of day.
    """
    hour = datetime.now().hour
    if 5 <= hour < 12:
        return "morning"
    elif 12 <= hour < 17:
        return "afternoon"
    elif 17 <= hour < 21:
        return "evening"
    else:
        return "night"


# =========================================================
# YOUR ACTUAL LLM (REPLACE THIS WITH REAL ONE)
# =========================================================
class MyLLM:
    """
    This represents YOUR internal / enterprise LLM.
    Replace the generate() method with:
    - Vertex AI
    - Azure
    - HF
    - Internal endpoint
    """

    def generate(self, prompt: str, tools: list | None = None):
        print("\nðŸ”µ LLM CALLED WITH PROMPT:\n", prompt)

        # Simulate tool decision
        if tools:
            return {
                "tool_call": {
                    "name": "get_time_of_day",
                    "arguments": {}
                }
            }

        # Final generation
        return "Hello ðŸ‘‹ (generated by your LLM)"


# =========================================================
# CUSTOM MODEL (THIS IS WHERE LLM IS INVOKED)
# =========================================================
class CustomModel:
    """
    agent-framework will call invoke().
    THIS is where your LLM must be used.
    """

    def __init__(self, llm: MyLLM):
        self.llm = llm

    async def invoke(
        self,
        messages,
        *,
        tools=None,
        tool_result=None,
        **kwargs,
    ):
        # Convert messages to text prompt
        if isinstance(messages, list):
            prompt = "\n".join(
                m.content for m in messages if hasattr(m, "content")
            )
        else:
            prompt = messages

        # -------------------------------------------------
        # FIRST PASS â†’ LLM decides whether to call tool
        # -------------------------------------------------
        if tools and tool_result is None:
            llm_response = self.llm.generate(prompt, tools=tools)
            return {
                "role": "assistant",
                "tool_call": llm_response["tool_call"],
            }

        # -------------------------------------------------
        # SECOND PASS â†’ tool result available
        # -------------------------------------------------
        if tool_result is not None:
            prompt = f"""
{prompt}

Tool result:
{tool_result}
"""

        final_text = self.llm.generate(prompt)

        return ChatMessage(
            role=Role.ASSISTANT,
            content=final_text,
        )


# =========================================================
# GREETING AGENT
# =========================================================
class GreetingAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            name="GreetingAgent",
            description="Time-based greeting agent",
            instructions=(
                "You are a friendly greeting assistant. "
                "Use tools when helpful."
            ),
            model=CustomModel(MyLLM()),     # ðŸ‘ˆ YOUR MODEL
            tools=[get_time_of_day],        # ðŸ‘ˆ TOOL
        )

    def greetings_prompt(self, user_input: Any) -> str:
        return f"""
You are a friendly greeting assistant.
Greet the user politely based on time of day.

User input:
{user_input}
"""

    async def run(
        self,
        messages: str | ChatMessage | list[str] | list[ChatMessage] | None = None,
        *,
        thread: AgentThread | None = None,
        **kwargs: Any,
    ) -> AgentRunResponse:

        prompt_template = ChatPromptTemplate.from_messages([
            ("human", self.greetings_prompt(messages)),
        ])

        prompt_str = prompt_template.format_prompt().to_string()

        # ðŸ”‘ FRAMEWORK CALLS CustomModel.invoke()
        return await super().run(
            prompt_str,
            thread=thread,
            **kwargs,
        )


# =========================================================
# RUN IN NOTEBOOK
# =========================================================
async def main():
    agent = GreetingAgent()
    response = await agent.run("Hi")
    print("\nðŸŸ¢ FINAL RESPONSE:\n", response.messages[0].content)

await main()
