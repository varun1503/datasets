import re
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize

def preprocess_and_stem(sentences):
    """Preprocess a list of sentences by lowercasing, removing punctuation, stripping spaces, and applying stemming."""
    stemmer = PorterStemmer()
    processed = []
    
    for sentence in sentences:
        sentence = sentence.lower()  # Convert to lowercase
        sentence = re.sub(r"[^\w\s]", "", sentence)  # Remove punctuation
        words = word_tokenize(sentence)  # Tokenize sentence
        stemmed_words = [stemmer.stem(word) for word in words]  # Apply stemming
        processed.append(" ".join(stemmed_words))  # Join words back into a sentence
    
    return processed

# Example usage:
sentences = ["Running quickly towards the finish line!", "This is a demonstration of stemming."]
print(preprocess_and_stem(sentences))
