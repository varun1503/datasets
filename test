Understanding Cohen's H in Feature Drift Analysis

Cohen's H is a statistical measure that quantifies the difference between two proportions. It is often used in NLP and machine learning to detect feature drift, where the distribution of features (such as words in text data) changes over time.

Formula for Cohen’s H

h = 2 \times (\arcsin(\sqrt{P}) - \arcsin(\sqrt{Q}))

Where:

 is the proportion of a keyword in the test dataset

 is the proportion of a keyword in the training dataset


Interpreting Cohen’s H Values

Cohen’s H follows a standard scale to determine drift significance:

In your implementation, drift is marked "Yes" if , meaning there is a noticeable shift in keyword distribution between the training and test datasets.

How to Use Cohen’s H for TF-IDF Feature Drift?

If Cohen's H is low (<0.2), the keyword appears with similar frequency in both training and test data, meaning no significant drift.

If Cohen's H is high (>0.2), the keyword is used differently in test data compared to training data, indicating a drift.

The confidence interval helps quantify the uncertainty in the Cohen's H estimation.


Would you like help fixing the syntax errors in your code?

