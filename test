import re
import json
import unicodedata
import os
import pandas as pd
from typing import List, Dict, Tuple, Optional
from docx import Document
from collections import OrderedDict
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
from docx.table import Table
from docx.text.paragraph import Paragraph


def norm(s: str) -> str:
    """Normalize text: handle unicode, whitespace"""
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()


def group_blocks_from_list(
    lines: List[str],
    start_rx: re.Pattern,
    stop_rx: Optional[re.Pattern] = None,
    stop_substrings: Optional[List[str]] = None,
    joiner: str = " ",
    include_stop_line: bool = False,
) -> List[Tuple[int, int, str]]:
    """Group consecutive lines from a list into blocks."""
    stop_substrings = stop_substrings or []
    grouped_blocks = []
    buf = []
    capturing = False
    start_idx = 0

    def flush(end_idx):
        nonlocal buf
        if buf:
            grouped_text = joiner.join(s.strip() for s in buf if s.strip())
            grouped_blocks.append((start_idx, end_idx, grouped_text))
            buf = []

    for i, line in enumerate(lines):
        s = (line or "").strip()
        if start_rx.search(s):
            if capturing:
                flush(i - 1)
            capturing = True
            start_idx = i
            buf = [s]
            continue

        if not capturing:
            continue

        buf.append(s)

        stop_hit = False
        if stop_rx and stop_rx.search(s):
            stop_hit = True
        elif any(sub in s for sub in stop_substrings):
            stop_hit = True

        if stop_hit:
            if not include_stop_line:
                buf.pop()
                flush(i - 1)
            else:
                flush(i)
            capturing = False

    if capturing:
        flush(len(lines) - 1)

    return grouped_blocks


def replace_blocks_in_lines(lines: List[str], grouped_blocks: List[Tuple[int, int, str]]) -> List[str]:
    """Replace original RFR block lines with their grouped version."""
    replaced = []
    i = 0
    block_map = {start: (end, text) for start, end, text in grouped_blocks}

    while i < len(lines):
        if i in block_map:
            end_idx, text = block_map[i]
            replaced.append(text)
            i = end_idx + 1
        else:
            replaced.append(lines[i])
            i += 1
    return replaced


def read_docx_lines(path: str) -> List[str]:
    """Read Word document and return list of text lines."""
    doc = Document(path)
    lines: List[str] = []

    for child in doc.element.body.iterchildren():
        if child.tag == qn("w:p"):
            p = Paragraph(child, doc)
            t = norm(p.text)
            if t:
                lines.append(t)
        elif child.tag == qn("w:tbl"):
            tbl = Table(child, doc)
            for row in tbl.rows:
                row_text = []
                for cell in row.cells:
                    for p in cell.paragraphs:
                        t = norm(p.text)
                        if t:
                            row_text.append(t)
                if row_text:
                    lines.append(" | ".join(row_text))

    # Group RFR blocks
    RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)
    STOP_SUBS = ["[Modeling Team's Response]", "[", "Modeling Team's Response"]
    blocks = group_blocks_from_list(lines, start_rx=RFR_RX, stop_substrings=STOP_SUBS, include_stop_line=False)
    final_lines = replace_blocks_in_lines(lines, blocks)

    return final_lines


# Patterns
REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)
RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)
BRACKETS_RX = re.compile(r"<\s*([^>]+?)\s*>")
Q_KEY_RX = re.compile(r"^\s*Q\d+\s*:\s*", re.IGNORECASE)
RESP_HDR_RX = re.compile(r"Modeling Team['']?s Response", re.IGNORECASE)
TEST_TAG_RX = re.compile(r"^Test\s*(\w+)", re.IGNORECASE)


def extract_meta_from_rfr_header(line: str) -> Tuple[str, str, str]:
    """
    Extract metadata from RFR header with improved logic:
    - Handles missing '?' in IMVP questions
    - Better section extraction
    """
    q_key = ""
    section = ""
    imvp = ""
    
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    
    if not parts:
        return q_key, section, imvp
    
    # Extract Q key (e.g., "Q2:")
    for part in parts:
        if Q_KEY_RX.match(part):
            q_key = part
            break
    
    # NEW LOGIC: Better IMVP extraction
    # Look for longest bracketed content that's not Q-key and not short tags
    candidates = [p for p in parts if p != q_key and len(p) > 20]
    
    # Prefer parts ending with '?' but accept longest if none found
    question_parts = [p for p in candidates if p.endswith("?")]
    if question_parts:
        imvp = max(question_parts, key=len)
    elif candidates:
        # If no '?' found, take the longest substantial text
        imvp = max(candidates, key=len)
    
    # Extract section: look for short descriptive tags
    section_candidates = [
        p for p in parts 
        if p != q_key 
        and p != imvp 
        and len(p) < 50 
        and not p.endswith("?")
    ]
    
    # Common section patterns
    section_keywords = ["validation", "data", "model", "performance", "documentation", "testing"]
    for part in section_candidates:
        if any(keyword in part.lower() for keyword in section_keywords):
            section = part
            break
    
    # If no section found yet, take first short non-question part
    if not section and section_candidates:
        section = section_candidates[0]
    
    return q_key, section, imvp


def extract_test_tag(line: str) -> Optional[str]:
    """Extract test tag from line."""
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    for part in parts:
        m = TEST_TAG_RX.match(part)
        if m:
            tag_value = m.group(1).lower()
            return f"test{tag_value}"
    return None


def clean_greater_than(lines: List[str]) -> List[str]:
    """Remove trailing '>' from lines."""
    return [re.sub(r'>.*$', '', s).strip() for s in lines]


def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    """Parse lines into structured RFR rows."""
    # Find start after "Request Items"
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    
    L = lines[start:]
    rows: List[Dict] = []
    i = 0
    
    while i < len(L):
        line = L[i]
        if RFR_RX.search(line):
            q_key, section, imvp_q = extract_meta_from_rfr_header(line)
            test_tag = extract_test_tag(line)
            
            # Extract RFR number for fallback Q-key
            rfr_match = re.search(r"RFR\s*(\d+)", line, re.IGNORECASE)
            rfr_num = rfr_match.group(1) if rfr_match else "?"
            
            # If no Q-key found, create one from RFR number
            if not q_key:
                q_key = f"Q{rfr_num}:"
            
            responses: List[str] = []
            i += 1
            
            # Collect responses
            while i < len(L) and not RFR_RX.search(L[i]):
                cur = L[i]
                if RESP_HDR_RX.search(cur):
                    i += 1
                    block: List[str] = []
                    while (
                        i < len(L)
                        and not RESP_HDR_RX.search(L[i])
                        and not RFR_RX.search(L[i])
                    ):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    # Unwrap <...> if entire block is wrapped
                    m = BRACKETS_RX.fullmatch(resp)
                    if m:
                        resp = norm(m.group(1))
                    if resp:
                        responses.append(resp)
                    continue
                i += 1
            
            responses = clean_greater_than(responses)
            
            # Build row - always include if we have IMVP or responses
            if imvp_q or responses:
                row = {
                    "IMVP Question": imvp_q or "",
                    "Section": section or "N/A",
                    "rfr": {q_key: " ".join(responses).strip()}
                }
                if test_tag:
                    row[test_tag] = imvp_q or ""
                rows.append(row)
            continue
        i += 1
    
    return rows


def parse_docx_to_rfr_rows(path: str) -> List[Dict]:
    """Main entry point: parse DOCX to RFR rows."""
    return parse_lines_after_request_items(read_docx_lines(path))


def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    """Merge rows with empty IMVP into previous row (same section)."""
    out: List[Dict] = []
    last_with_imvp_by_section: dict = {}
    
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            # Empty IMVP; try to merge
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
            # Skip rows that can't be merged
    
    return out


def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    """Merge rows with identical IMVP questions."""
    merged: "OrderedDict[str, Dict]" = OrderedDict()
    
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "N/A",
                "rfr": dict(r.get("rfr") or {})
            }
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if merged[imvp]["Section"] == "N/A" and r.get("Section"):
                merged[imvp]["Section"] = r["Section"]
    
    return list(merged.values())


def flatten_rfr_for_csv(rows: List[Dict]) -> List[Dict]:
    """Flatten rfr dict into separate columns for CSV."""
    flattened = []
    for r in rows:
        base = {
            "IMVP Question": r.get("IMVP Question", ""),
            "Section": r.get("Section", "N/A")
        }
        
        # Add test tags if present
        for key in r:
            if key.startswith("test"):
                base[key] = r[key]
        
        # Flatten rfr dict
        rfr_dict = r.get("rfr", {})
        for q_key, response in rfr_dict.items():
            row_copy = base.copy()
            row_copy["Q_Key"] = q_key
            row_copy["Response"] = response
            flattened.append(row_copy)
    
    return flattened


def convert_csv(rows: List[Dict], document_path: str) -> pd.DataFrame:
    """Convert rows to DataFrame with metadata."""
    file_name = os.path.basename(document_path)
    
    # Flatten for CSV
    flattened = flatten_rfr_for_csv(rows)
    
    df = pd.DataFrame(flattened)
    df["file_name"] = file_name
    df["type"] = "rfr"
    
    return df


def save_outputs(rows: List[Dict], document_path: str, json_path: str = None, csv_path: str = None):
    """Save both JSON and CSV outputs."""
    base_name = os.path.splitext(os.path.basename(document_path))[0]
    
    # Save JSON
    if json_path is None:
        json_path = f"{base_name}_rfr_output.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(rows, f, ensure_ascii=False, indent=2)
    print(f"âœ“ Saved JSON: {json_path} ({len(rows)} rows)")
    
    # Save CSV
    if csv_path is None:
        csv_path = f"{base_name}_rfr_output.csv"
    df = convert_csv(rows, document_path)
    df.to_csv(csv_path, index=False, encoding="utf-8")
    print(f"âœ“ Saved CSV: {csv_path} ({len(df)} rows)")
    
    return json_path, csv_path


if __name__ == "__main__":
    DOCX_PATH = "sample_RFR.docx"
    
    # Parse document
    rows = parse_docx_to_rfr_rows(DOCX_PATH)
    
    print(f"\nðŸ“„ Parsed {len(rows)} initial rows")
    
    # Optional: Apply merging logic
    # rows = collapse_empty_imvp_into_previous(rows)
    # rows = merge_rows_by_imvp(rows)
    
    # Save outputs
    json_file, csv_file = save_outputs(rows, DOCX_PATH)
    
    # Display sample
    print("\nðŸ“‹ Sample output:")
    print(json.dumps(rows[0] if rows else {}, indent=2, ensure_ascii=False))            return True
    return False

def remove_placeholder_paragraphs(doc):
    """
    Remove entire paragraphs that contain placeholder text
    """
    removed_count = 0
    paragraphs_to_remove = []
    
    for para in doc.paragraphs:
        text = para.text.strip()
        if text and contains_placeholder_text(text):
            paragraphs_to_remove.append(para)
    
    for para in paragraphs_to_remove:
        p_element = para._element
        p_element.getparent().remove(p_element)
        removed_count += 1
    
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                cell_paragraphs_to_remove = []
                for para in cell.paragraphs:
                    text = para.text.strip()
                    if text and contains_placeholder_text(text):
                        cell_paragraphs_to_remove.append(para)
                
                for para in cell_paragraphs_to_remove:
                    p_element = para._element
                    p_element.getparent().remove(p_element)
                    removed_count += 1
    
    return removed_count

def clean_placeholder_text_from_runs(para):
    """
    Clean placeholder text from within a paragraph (if it's part of larger text)
    """
    full_text = para.text
    
    if not contains_placeholder_text(full_text):
        return False
    
    placeholder_pattern = r'[\{\[]?\s*put\s+model(?:l?ing)?\s+team\'?s?\s+response\s+here\s*[\}\]]?'
    
    new_text = re.sub(placeholder_pattern, '', full_text, flags=re.IGNORECASE)
    new_text = re.sub(r'\s+', ' ', new_text).strip()
    
    if new_text != full_text:
        for run in para.runs:
            run.text = ''
        
        if para.runs:
            para.runs[0].text = new_text
        elif new_text:
            para.add_run(new_text)
        
        return True
    
    return False

def remove_all_placeholders(doc):
    """
    Remove placeholder tags
    """
    remove_placeholder_paragraphs(doc)
    
    for para in doc.paragraphs:
        clean_placeholder_text_from_runs(para)
    
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for para in cell.paragraphs:
                    clean_placeholder_text_from_runs(para)

def remove_empty_paragraphs_between_caption_and_content(doc):
    """
    Remove empty paragraphs between captions and their tables/figures
    """
    body = doc.element.body
    elements = list(body)
    paragraphs_to_remove = []
    
    for i, element in enumerate(elements):
        if element.tag.endswith('p'):
            for para in doc.paragraphs:
                if para._element == element:
                    text = para.text.strip()
                    
                    if re.match(r'^\s*Table\s+[\d.]+', text, re.IGNORECASE):
                        j = i + 1
                        while j < len(elements):
                            next_elem = elements[j]
                            
                            if next_elem.tag.endswith('tbl'):
                                break
                            
                            if next_elem.tag.endswith('p'):
                                for p in doc.paragraphs:
                                    if p._element == next_elem:
                                        if is_empty_paragraph(p):
                                            paragraphs_to_remove.append(p)
                                        else:
                                            j = len(elements)
                                        break
                            j += 1
                    
                    elif re.match(r'^\s*Figure\s+[\d.]+', text, re.IGNORECASE):
                        j = i + 1
                        while j < len(elements):
                            next_elem = elements[j]
                            
                            if next_elem.tag.endswith('p'):
                                has_image = False
                                for p in doc.paragraphs:
                                    if p._element == next_elem:
                                        has_image = any(run._element.xpath('.//pic:pic') for run in p.runs)
                                        if has_image:
                                            j = len(elements)
                                        elif is_empty_paragraph(p):
                                            paragraphs_to_remove.append(p)
                                        else:
                                            j = len(elements)
                                        break
                            
                            if next_elem.tag.endswith('tbl'):
                                break
                            
                            j += 1
                    break
    
    for para in paragraphs_to_remove:
        p_element = para._element
        p_element.getparent().remove(p_element)

def move_all_misplaced_captions(doc):
    """
    Scan entire document and move ANY caption that appears after its content to before it
    """
    body = doc.element.body
    elements = list(body)
    
    i = 0
    
    while i < len(elements):
        element = elements[i]
        
        # Check if this is a table
        if element.tag.endswith('tbl'):
            # Check if there's already a caption immediately before
            has_caption_before = False
            if i > 0:
                prev_elem = elements[i - 1]
                if prev_elem.tag.endswith('p'):
                    for para in doc.paragraphs:
                        if para._element == prev_elem:
                            if re.match(r'^\s*Table\s+[\d.]+', para.text.strip(), re.IGNORECASE):
                                has_caption_before = True
                            break
            
            # If no caption before, search FORWARD up to 30 elements
            if not has_caption_before:
                for offset in range(1, 31):
                    if i + offset < len(elements):
                        check_elem = elements[i + offset]
                        
                        if check_elem.tag.endswith('p'):
                            for para in doc.paragraphs:
                                if para._element == check_elem:
                                    text = para.text.strip()
                                    if re.match(r'^\s*Table\s+[\d.]+', text, re.IGNORECASE):
                                        # Found a table caption after the table - move it before
                                        check_elem.getparent().remove(check_elem)
                                        element.addprevious(check_elem)
                                        # Reload elements
                                        elements = list(body)
                                        i = 0  # Restart from beginning
                                        break
                                break
                        
                        # Stop if we hit another table
                        if check_elem.tag.endswith('tbl'):
                            break
        
        # Check if this is a figure (paragraph with image)
        elif element.tag.endswith('p'):
            has_image = False
            for para in doc.paragraphs:
                if para._element == element:
                    has_image = any(run._element.xpath('.//pic:pic') for run in para.runs)
                    break
            
            if has_image:
                # Check if there's already a caption immediately before
                has_caption_before = False
                if i > 0:
                    prev_elem = elements[i - 1]
                    if prev_elem.tag.endswith('p'):
                        for para in doc.paragraphs:
                            if para._element == prev_elem:
                                if re.match(r'^\s*Figure\s+[\d.]+', para.text.strip(), re.IGNORECASE):
                                    has_caption_before = True
                                break
                
                # If no caption before, search FORWARD up to 30 elements
                if not has_caption_before:
                    for offset in range(1, 31):
                        if i + offset < len(elements):
                            check_elem = elements[i + offset]
                            
                            if check_elem.tag.endswith('p'):
                                for para in doc.paragraphs:
                                    if para._element == check_elem:
                                        text = para.text.strip()
                                        if re.match(r'^\s*Figure\s+[\d.]+', text, re.IGNORECASE):
                                            # Found a figure caption after the figure - move it before
                                            check_elem.getparent().remove(check_elem)
                                            element.addprevious(check_elem)
                                            # Reload elements
                                            elements = list(body)
                                            i = 0  # Restart from beginning
                                            break
                                    break
                            
                            # Stop if we hit a table or another figure
                            if check_elem.tag.endswith('tbl'):
                                break
                            
                            if check_elem.tag.endswith('p'):
                                for p in doc.paragraphs:
                                    if p._element == check_elem:
                                        if any(run._element.xpath('.//pic:pic') for run in p.runs):
                                            break
                                    break
        
        i += 1

def renumber_captions(doc_path, output_path):
    """
    Renumber all table and figure captions sequentially
    """
    doc = Document(doc_path)
    
    # Step 1: Move ALL misplaced captions (run multiple times to catch all cases)
    for iteration in range(5):
        move_all_misplaced_captions(doc)
        doc.save(output_path)
        doc = Document(output_path)
    
    # Step 2: Remove empty paragraphs
    remove_empty_paragraphs_between_caption_and_content(doc)
    doc.save(output_path)
    doc = Document(output_path)
    
    # Step 3: Remove placeholders
    remove_all_placeholders(doc)
    doc.save(output_path)
    doc = Document(output_path)
    
    body = doc.element.body
    elements = list(body)
    
    # Step 4: Add missing captions for tables (using improved logic)
    for i, element in enumerate(elements):
        if not element.tag.endswith('tbl'):
            continue

        prev_el = elements[i - 1] if i > 0 else None
        has_caption = False

        if prev_el is not None and prev_el.tag.endswith('p'):
            cap_para = next((p for p in doc.paragraphs if p._element == prev_el), None)
            if cap_para and is_real_caption(cap_para.text, "table"):
                has_caption = True

        if not has_caption:
            new_para = parse_xml(
                r'<w:p xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                r'<w:r><w:t>Table PLACEHOLDER</w:t></w:r></w:p>'
            )
            element.addprevious(new_para)
    
    doc.save(output_path)
    doc = Document(output_path)
    body = doc.element.body
    elements = list(body)

    # Step 5: Add missing captions for figures (using improved logic)
    for i, element in enumerate(elements):
        if not element.tag.endswith('p'):
            continue

        para = next((p for p in doc.paragraphs if p._element == element), None)
        if not para:
            continue

        has_image = any(run._element.xpath('.//pic:pic') for run in para.runs)
        if not has_image:
            continue

        prev_el = elements[i - 1] if i > 0 else None
        has_caption = False

        if prev_el is not None and prev_el.tag.endswith('p'):
            cap_para = next((p for p in doc.paragraphs if p._element == prev_el), None)
            if cap_para and is_real_caption(cap_para.text, "figure"):
                has_caption = True

        if not has_caption:
            new_para = parse_xml(
                r'<w:p xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">'
                r'<w:r><w:t>Figure PLACEHOLDER</w:t></w:r></w:p>'
            )
            element.addprevious(new_para)
    
    doc.save(output_path)
    doc = Document(output_path)
    body = doc.element.body
    elements = list(body)
    
    # Step 6: Renumber all captions sequentially
    table_num = 1
    figure_num = 1
    
    for i, element in enumerate(elements):
        if element.tag.endswith('p'):
            current_para = None
            for para in doc.paragraphs:
                if para._element == element:
                    current_para = para
                    break
            
            if current_para:
                text = current_para.text.strip()
                
                # Find the next non-empty element
                next_element = None
                for offset in range(1, 10):
                    if i + offset < len(elements):
                        candidate = elements[i + offset]
                        
                        if candidate.tag.endswith('tbl'):
                            next_element = candidate
                            break
                        
                        if candidate.tag.endswith('p'):
                            for p in doc.paragraphs:
                                if p._element == candidate:
                                    if p.text.strip() or any(run._element.xpath('.//pic:pic') for run in p.runs):
                                        next_element = candidate
                                        break
                            if next_element:
                                break
                
                # Renumber table captions
                if re.search(r'\bTable\s+(?:PLACEHOLDER|[\d.]+)', text, re.IGNORECASE):
                    if next_element is not None and next_element.tag.endswith('tbl'):
                        if is_actual_caption(text, True) or 'PLACEHOLDER' in text:
                            is_placeholder = 'PLACEHOLDER' in text
                            
                            match = re.search(r'\bTable\s+(?:PLACEHOLDER|[\d.]+)\s*:?\s*(.*)', text, re.IGNORECASE)
                            description = match.group(1).strip() if match else ''
                            
                            if is_placeholder:
                                current_para.text = f'Table {table_num} {{placeholder}}'
                            elif description:
                                current_para.text = f'Table {table_num}: {description}'
                            else:
                                current_para.text = f'Table {table_num}'
                            
                            table_num += 1
                
                # Renumber figure captions
                elif re.search(r'\bFigure\s+(?:PLACEHOLDER|[\d.]+)', text, re.IGNORECASE):
                    if next_element is not None and next_element.tag.endswith('p'):
                        for para in doc.paragraphs:
                            if para._element == next_element:
                                has_image = any(run._element.xpath('.//pic:pic') for run in para.runs)
                                if has_image and (is_actual_caption(text, True) or 'PLACEHOLDER' in text):
                                    is_placeholder = 'PLACEHOLDER' in text
                                    
                                    match = re.search(r'\bFigure\s+(?:PLACEHOLDER|[\d.]+)\s*:?\s*(.*)', text, re.IGNORECASE)
                                    description = match.group(1).strip() if match else ''
                                    
                                    if is_placeholder:
                                        current_para.text = f'Figure {figure_num} {{placeholder}}'
                                    elif description:
                                        current_para.text = f'Figure {figure_num}: {description}'
                                    else:
                                        current_para.text = f'Figure {figure_num}'
                                    
                                    figure_num += 1
                                break
    
    doc.save(output_path)

# Usage
if __name__ == "__main__":
    input_file = "buisness.docx"
    output_file = "buisness_renumbered2.docx"
    
    renumber_captions(input_file, output_file)
```

**Key changes:**

1. **Added `is_real_caption()` function** - A cleaner function that takes content_type parameter ("table" or "figure")

2. **Updated Step 4 (tables)** - Now uses the improved logic with `next()` and `is_real_caption()` for checking table captions

3. **Updated Step 5 (figures)** - Uses the same improved logic you provided for checking figure captions

4. **Consistent approach** - Both tables and figures now use the same clean, efficient logic pattern

The code now handles both tables and figures with the improved logic you demonstrated, making it more robust and consistent.
