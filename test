import re
import json
import unicodedata
import os
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from collections import OrderedDict

import pandas as pd
from docx import Document
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
from docx.table import Table
from docx.text.paragraph import Paragraph


# ==================== TEXT NORMALIZATION ====================

def norm(s: str) -> str:
    """Normalize unicode and whitespace in text."""
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()


def clean_greater_than(lines: List[str]) -> List[str]:
    """Remove everything after '>' in each line."""
    return [re.sub(r'>.*$', '', s).strip() for s in lines]


# ==================== BLOCK GROUPING ====================

def group_blocks_from_list(
    lines: List[str],
    start_rx: re.Pattern,
    stop_rx: Optional[re.Pattern] = None,
    stop_substrings: Optional[List[str]] = None,
    joiner: str = " ",
    include_stop_line: bool = False,
) -> List[Tuple[int, int, str]]:
    """
    Group consecutive lines into blocks based on start/stop patterns.
    
    Returns:
        List of tuples (start_idx, end_idx, grouped_text)
    """
    stop_substrings = stop_substrings or []
    grouped_blocks = []
    buf = []
    capturing = False
    start_idx = 0

    def flush(end_idx: int) -> None:
        nonlocal buf
        if buf:
            grouped_text = joiner.join(s.strip() for s in buf if s.strip())
            grouped_blocks.append((start_idx, end_idx, grouped_text))
            buf = []

    for i, line in enumerate(lines):
        s = (line or "").strip()
        
        # Start new block
        if start_rx.search(s):
            if capturing:
                flush(i - 1)
            capturing = True
            start_idx = i
            buf = [s]
            continue

        if not capturing:
            continue

        buf.append(s)

        # Check for stop conditions
        stop_hit = False
        if stop_rx and stop_rx.search(s):
            stop_hit = True
        elif any(sub in s for sub in stop_substrings):
            stop_hit = True

        if stop_hit:
            if not include_stop_line:
                buf.pop()
                flush(i - 1)
            else:
                flush(i)
            capturing = False

    # Flush remaining buffer
    if capturing:
        flush(len(lines) - 1)

    return grouped_blocks


def replace_blocks_in_lines(
    lines: List[str], 
    grouped_blocks: List[Tuple[int, int, str]]
) -> List[str]:
    """Replace original block lines with their grouped versions."""
    replaced = []
    i = 0
    block_map = {start: (end, text) for start, end, text in grouped_blocks}

    while i < len(lines):
        if i in block_map:
            end_idx, text = block_map[i]
            replaced.append(text)
            i = end_idx + 1
        else:
            replaced.append(lines[i])
            i += 1
    return replaced


# ==================== DOCX READING ====================

def read_docx_lines(path: str) -> List[str]:
    """
    Extract all text lines from a Word document in order.
    Handles both paragraphs and tables.
    """
    doc = Document(path)
    lines: List[str] = []

    # Compile patterns
    RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)
    STOP_SUBS = ["[Modeling Team's Response]", "[", "Modeling Team's Response"]

    # Walk through document body in order
    for child in doc.element.body.iterchildren():
        if child.tag == qn("w:p"):  # Paragraph
            p = Paragraph(child, doc)
            t = norm(p.text)
            if t:
                lines.append(t)

        elif child.tag == qn("w:tbl"):  # Table
            tbl = Table(child, doc)
            for row in tbl.rows:
                row_text = []
                for cell in row.cells:
                    for p in cell.paragraphs:
                        t = norm(p.text)
                        if t:
                            row_text.append(t)
                if row_text:
                    lines.append(" | ".join(row_text))

    # Group RFR blocks
    blocks = group_blocks_from_list(
        lines, 
        start_rx=RFR_RX, 
        stop_substrings=STOP_SUBS,
        include_stop_line=False
    )
    final_lines = replace_blocks_in_lines(lines, blocks)

    return final_lines


# ==================== PATTERN MATCHING ====================

# Compiled patterns (defined once for efficiency)
REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)
RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)
BRACKETS_RX = re.compile(r"<\s*([^>]+?)\s*>")
Q_KEY_RX = re.compile(r"^\s*Q\d+\s*:\s*", re.IGNORECASE)
F_KEY_RX = re.compile(r"^\s*F\d+\s*:\s*", re.IGNORECASE)
RESP_HDR_RX = re.compile(r"Modell?ing Team['']?s Response", re.IGNORECASE)
TEST_TAG_RX = re.compile(r"^Test\s*(\w+)", re.IGNORECASE)


def extract_meta_from_rfr_header(line: str) -> Tuple[str, str, str]:
    """
    Extract RFR question, Section, and IMVP question from RFR header.
    
    Returns:
        Tuple of (rfr_question, section, imvp_question)
    """
    rfr_question = ""
    section = ""
    imvp = ""
    
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    
    # Find RFR question (starts with Q1:, Q2:, etc.)
    for part in parts:
        if Q_KEY_RX.match(part):
            # Extract everything after "Q3: " -> "MRMG would like to know..."
            rfr_question = Q_KEY_RX.sub('', part).strip()
            break
    
    # Find IMVP question (last '?' that's not the RFR question)
    all_questions = [p for p in parts if p.endswith("?")]
    # Remove the RFR question from candidates
    imvp_candidates = [q for q in all_questions if Q_KEY_RX.sub('', q).strip() != rfr_question]
    if imvp_candidates:
        imvp = imvp_candidates[-1]
    
    # Find Section (first non-question bracket)
    for part in parts:
        if not part.endswith("?"):
            section = part
            break
    
    # Fallback: shortest non-question part
    if not section:
        non_q = [p for p in parts if not p.endswith("?")]
        if non_q:
            section = sorted(non_q, key=len)[0]
    
    return rfr_question, section, imvp


def extract_test_tag(line: str) -> Optional[str]:
    """Extract test tag from line (e.g., 'TestA' -> 'testa')."""
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    for part in parts:
        m = TEST_TAG_RX.match(part)
        if m:
            tag_value = m.group(1).lower()
            return f"test{tag_value}"
    return None


def extract_f_key_and_description(line: str) -> Optional[str]:
    """Extract F-item description from line (e.g., '<F1:Amex US SBS...' -> 'Amex US SBS...')."""
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    for part in parts:
        m = F_KEY_RX.match(part)
        if m:
            # Extract everything after 'F1:', 'F2:', etc.
            if ':' in part:
                description = part.split(':', 1)[1].strip()
                return description
            return part
    return None


# ==================== PARSING ====================

def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    """
    Parse lines into structured RFR rows with nested F-items.
    
    Returns:
        List of dictionaries with IMVP Question, Section, and nested rfr responses
    """
    # Find start position after "Request Items"
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    
    L = lines[start:]
    rows: List[Dict] = []
    i = 0
    
    while i < len(L):
        line = L[i]
        
        # Check if line is an RFR header
        if RFR_RX.search(line):
            rfr_question, section, imvp_q = extract_meta_from_rfr_header(line)
            test_tag = extract_test_tag(line)
            
            # Initialize nested structure for RFR-question -> F-description -> response
            q_responses: Dict[str, str] = {}
            i += 1
            
            # Collect all F-items and responses for this RFR
            current_f_description = None
            
            while i < len(L) and not RFR_RX.search(L[i]):
                cur = L[i]
                
                # Check if this line has an F-item description
                f_desc = extract_f_key_and_description(cur)
                if f_desc:
                    current_f_description = f_desc
                    i += 1
                    continue
                
                # Found a response header
                if RESP_HDR_RX.search(cur):
                    i += 1
                    block: List[str] = []
                    
                    # Collect response content
                    while (
                        i < len(L)
                        and not RESP_HDR_RX.search(L[i])
                        and not RFR_RX.search(L[i])
                        and not extract_f_key_and_description(L[i])  # Stop at next F-item
                    ):
                        block.append(L[i])
                        i += 1
                    
                    resp = norm(" ".join(block))
                    
                    # Unwrap <...> if entire block is wrapped
                    m = BRACKETS_RX.fullmatch(resp)
                    if m:
                        resp = norm(m.group(1))
                    
                    if resp:
                        # Store response under the current F-description
                        if current_f_description:
                            q_responses[current_f_description] = resp
                        else:
                            # If no F-description, store directly (backward compatibility)
                            q_responses["response"] = resp
                    continue
                
                i += 1
            
            # Clean responses
            cleaned_responses = {k: re.sub(r'>.*$', '', v).strip() 
                               for k, v in q_responses.items()}
            
            # Only emit row if we have IMVP or responses
            if (imvp_q and imvp_q.strip()) or cleaned_responses:
                row = {
                    "IMVP Question": imvp_q or "",
                    "Section": section or "",
                    "rfr": {(rfr_question or "No RFR question"): cleaned_responses},
                }
                
                # Add test tag if found
                if test_tag:
                    row[test_tag] = imvp_q or ""
                
                rows.append(row)
            continue
        
        i += 1
    
    return rows


def parse_docx_to_rfr_rows(path: str) -> List[Dict]:
    """Main entry point: parse DOCX file to RFR rows."""
    return parse_lines_after_request_items(read_docx_lines(path))


# ==================== ROW MERGING ====================

def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    """
    Merge rows with empty IMVP into the most recent row with the same Section
    that has a non-empty IMVP.
    """
    out: List[Dict] = []
    last_with_imvp_by_section: Dict[str, int] = {}
    
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            # Try to merge into previous row with same section
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
            # Skip rows that can't be merged
    
    return out


def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    """
    Merge rows with identical IMVP Question.
    Combines rfr entries and keeps first non-empty Section.
    """
    merged: OrderedDict[str, Dict] = OrderedDict()
    
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "",
                "rfr": dict(r.get("rfr") or {})
            }
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if not merged[imvp]["Section"] and (r.get("Section") or ""):
                merged[imvp]["Section"] = r["Section"]
    
    return list(merged.values())


# ==================== VALIDATION ====================

def validate_rows(rows: List[Dict]) -> List[Dict]:
    """
    Validate rows meet strict formatting requirements:
    - IMVP Question must exist and end with '?'
    - rfr map must have exactly one key
    - Response must be non-empty
    """
    for idx, r in enumerate(rows, start=1):
        imvp = (r.get("IMVP Question") or "").strip()
        rfr = r.get("rfr") or {}
        
        # Check IMVP question format
        if not imvp or not imvp.endswith("?"):
            qkeys = list(rfr.keys())
            raise ValueError(
                f"Document is not formatted correctly: row {idx} missing IMVP question "
                f"(found rfr keys={qkeys}). Header must include a <...?> block."
            )
        
        # Check rfr structure
        if not isinstance(rfr, dict) or len(rfr) != 1:
            raise ValueError(
                f"Document is not formatted correctly: row {idx} has invalid rfr map: {rfr}"
            )
        
        k, v = next(iter(rfr.items()))
        
        # Check for placeholder Q-IDs
        if k.strip() in {"Q?", "Q1", "Q2", "Q3", "Q4", "Q5"} and k.strip() != imvp:
            raise ValueError(
                f"Document is not formatted correctly: row {idx} uses Q-ID '{k}' "
                f"instead of the RFR question.\nIMVP: {imvp}\nrfr key: {k}"
            )
        
        # Check response is non-empty
        if not (v or "").strip():
            raise ValueError(
                f"Document is not formatted correctly: row {idx} has empty "
                f"Modeling Team response for '{imvp}'"
            )
    
    return rows


# ==================== OUTPUT ====================

def convert_to_dataframe(rows: List[Dict], document_path: str) -> pd.DataFrame:
    """Convert parsed rows to a pandas DataFrame."""
    file_name = os.path.basename(document_path)
    
    df = pd.DataFrame({"finding": rows})
    df["file name"] = file_name
    df["type"] = "rfr"
    
    return df


# ==================== MAIN ====================

def main():
    """Main execution function."""
    DOCX_PATH = "rfrtest.docx"
    OUT_JSON = "rfr_rows.json"
    OUT_CSV = "rfr_rows.csv"
    
    # Check file exists
    if not Path(DOCX_PATH).exists():
        print(f"Error: File '{DOCX_PATH}' not found")
        return
    
    try:
        # Parse document
        print(f"Parsing {DOCX_PATH}...")
        rows = parse_docx_to_rfr_rows(DOCX_PATH)
        print(f"Found {len(rows)} initial rows")
        
        # Process rows
        rows = collapse_empty_imvp_into_previous(rows)
        print(f"After collapsing: {len(rows)} rows")
        
        # Optionally validate (uncomment if needed)
        # rows = validate_rows(rows)
        
        # Save JSON
        with open(OUT_JSON, "w", encoding="utf-8") as f:
            for r in rows:
                f.write(json.dumps(r, ensure_ascii=False) + "\n")
        print(f"Saved {len(rows)} rows to {OUT_JSON}")
        
        # Save CSV
        df = convert_to_dataframe(rows, DOCX_PATH)
        df.to_csv(OUT_CSV, index=False)
        print(f"Saved DataFrame to {OUT_CSV}")
        
        # Display sample
        if rows:
            print("\nSample row:")
            print(json.dumps(rows[0], indent=2, ensure_ascii=False))
    
    except Exception as e:
        print(f"Error: {e}")
        raise


if __name__ == "__main__":
    main()
