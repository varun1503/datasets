import re
import json
import unicodedata
import os
import pandas as pd
from typing import List, Dict, Tuple, Optional
from docx import Document
from collections import OrderedDict
from docx.oxml.ns import qn
from docx.table import Table
from docx.text.paragraph import Paragraph


# ---------- HELPER FUNCTIONS ----------

def norm(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ")
    return re.sub(r"\s+", " ", s).strip()


def group_blocks_from_list(
    lines: List[str],
    start_rx: re.Pattern,
    stop_rx: Optional[re.Pattern] = None,
    stop_substrings: Optional[List[str]] = None,
    joiner: str = " ",
    include_stop_line: bool = False,
) -> List[Tuple[int, int, str]]:
    """Group consecutive lines from a list into blocks."""
    stop_substrings = stop_substrings or []
    grouped_blocks = []
    buf = []
    capturing = False
    start_idx = 0

    def flush(end_idx):
        nonlocal buf
        if buf:
            grouped_text = joiner.join(s.strip() for s in buf if s.strip())
            grouped_blocks.append((start_idx, end_idx, grouped_text))
            buf = []

    for i, line in enumerate(lines):
        s = (line or "").strip()
        if start_rx.search(s):
            if capturing:
                flush(i - 1)
            capturing = True
            start_idx = i
            buf = [s]
            continue

        if not capturing:
            continue

        buf.append(s)

        stop_hit = False
        if stop_rx and stop_rx.search(s):
            stop_hit = True
        elif any(sub in s for sub in stop_substrings):
            stop_hit = True

        if stop_hit:
            if not include_stop_line:
                buf.pop()
                flush(i - 1)
            else:
                flush(i)
            capturing = False

    if capturing:
        flush(len(lines) - 1)

    return grouped_blocks


def replace_blocks_in_lines(lines: List[str], grouped_blocks: List[Tuple[int, int, str]]) -> List[str]:
    """Replace original RFR block lines with their grouped version."""
    replaced = []
    i = 0
    block_map = {start: (end, text) for start, end, text in grouped_blocks}

    while i < len(lines):
        if i in block_map:
            end_idx, text = block_map[i]
            replaced.append(text)
            i = end_idx + 1
        else:
            replaced.append(lines[i])
            i += 1
    return replaced


def read_docx_lines(path: str) -> List[str]:
    doc = Document(path)
    lines: List[str] = []
    
    for child in doc.element.body.iterchildren():
        if child.tag == qn("w:p"):
            p = Paragraph(child, doc)
            t = norm(p.text)
            if t:
                lines.append(t)
        elif child.tag == qn("w:tbl"):
            tbl = Table(child, doc)
            for row in tbl.rows:
                row_text = []
                for cell in row.cells:
                    for p in cell.paragraphs:
                        t = norm(p.text)
                        if t:
                            row_text.append(t)
                if row_text:
                    lines.append(" | ".join(row_text))
    
    blocks = group_blocks_from_list(lines, start_rx=RFR_RX, stop_substrings=STOP_SUBS, include_stop_line=False)
    final_lines = replace_blocks_in_lines(lines, blocks)
    return final_lines


# ---------- REGEX PATTERNS ----------

REQ_ITEMS_RX = re.compile(r"^\s*Request\s+Items\s*$", re.IGNORECASE)
RFR_RX = re.compile(r"\s*RFR\s*\d+\s*", re.IGNORECASE)
BRACKETS_RX = re.compile(r"<\s*([^>]+?)\s*>")
Q_KEY_RX = re.compile(r"^\s*Q\d+\s*:\s*", re.IGNORECASE)
RESP_HDR_RX = re.compile(r"Modeling Team['']?s Response", re.IGNORECASE)
TEST_TAG_RX = re.compile(r"^Test\s*(\w+)", re.IGNORECASE)

STOP_SUBS = ["Modeling Team's Response", "Modeling Team's Response"]


# ---------- EXTRACTION ----------

def extract_meta_from_rfr_header(line: str) -> Tuple[str, str, str, str]:
    """Extract q_key, section, imvp, and test_tag from RFR header"""
    q_key = ""
    section = ""
    imvp = ""
    test_tag = None
    
    parts = [norm(x) for x in BRACKETS_RX.findall(line)]
    
    test_idx = -1
    q_idx = -1
    
    # Detect Q key
    for idx, part in enumerate(parts):
        if Q_KEY_RX.match(part):
            q_key = part
            q_idx = idx
            break
    
    # Detect Test tag
    for idx, part in enumerate(parts):
        m = TEST_TAG_RX.match(part)
        if m:
            tag_value = m.group(1).lower()
            test_tag = f"tests{tag_value}"
            test_idx = idx
            break
    
    # Last '?' (excluding q_key) is IMVP
    q_candidates = [p for p in parts if p.endswith("?") and p != q_key]
    if q_candidates:
        imvp = q_candidates[-1]
    
    # Section: first non-q, non-question, non-test after Q key
    if q_idx >= 0:
        for idx in range(q_idx + 1, len(parts)):
            part = parts[idx]
            if part == q_key or part.endswith("?") or idx == test_idx:
                continue
            section = part
            break
    
    # Fallback for section
    if not section:
        non_q = [p for idx, p in enumerate(parts) if p != q_key and not p.endswith("?") and idx != test_idx]
        if non_q:
            section = sorted(non_q, key=len)[0]
    
    return q_key, section, imvp, test_tag


def clean_greater_than(lines):
    return [re.sub(r'>.*$', '', s).strip() for s in lines]


def parse_lines_after_request_items(lines: List[str]) -> List[Dict]:
    start = 0
    for i, t in enumerate(lines):
        if REQ_ITEMS_RX.search(t):
            start = i + 1
            break
    
    L = lines[start:]
    rows: List[Dict] = []
    i = 0
    
    while i < len(L):
        line = L[i]
        if RFR_RX.search(line):
            q_key, section, imvp_q, test_tag = extract_meta_from_rfr_header(line)
            responses: List[str] = []
            i += 1
            
            while i < len(L) and not RFR_RX.search(L[i]):
                cur = L[i]
                if RESP_HDR_RX.search(cur):
                    i += 1
                    block: List[str] = []
                    while (
                        i < len(L)
                        and not RESP_HDR_RX.search(L[i])
                        and not RFR_RX.search(L[i])
                    ):
                        block.append(L[i])
                        i += 1
                    resp = norm(" ".join(block))
                    m = BRACKETS_RX.fullmatch(resp)
                    if m:
                        resp = norm(m.group(1))
                    if resp:
                        responses.append(resp)
                    continue
                i += 1
            
            responses = clean_greater_than(responses)
            
            if (imvp_q and imvp_q.strip()) or responses:
                row = {
                    "IMVP Question": imvp_q or "",
                    "Section": section or "",
                    "rfr": {(q_key or "Q?"): " ".join(responses).strip()},
                }
                # Add test tag if found
                if test_tag:
                    row[test_tag] = imvp_q or ""
                
                rows.append(row)
            continue
        i += 1
    
    return rows


def parse_docx_to_rfr_rows(path: str) -> List[Dict]:
    return parse_lines_after_request_items(read_docx_lines(path))


# ---------- MERGERS ----------

def collapse_empty_imvp_into_previous(rows: List[Dict]) -> List[Dict]:
    out: List[Dict] = []
    last_with_imvp_by_section: dict = {}
    
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        section = (r.get("Section") or "").strip()
        if imvp:
            out.append(r)
            last_with_imvp_by_section[section] = len(out) - 1
        else:
            idx = last_with_imvp_by_section.get(section)
            if idx is not None and r.get("rfr"):
                out[idx]["rfr"].update(r["rfr"])
    
    return out


def merge_rows_by_imvp(rows: List[Dict]) -> List[Dict]:
    merged: "OrderedDict[str, Dict]" = OrderedDict()
    
    for r in rows:
        imvp = (r.get("IMVP Question") or "").strip()
        if not imvp:
            continue
        
        if imvp not in merged:
            merged[imvp] = {
                "IMVP Question": imvp,
                "Section": r.get("Section") or "",
                "rfr": dict(r.get("rfr") or {})
            }
            # Copy test tag keys
            for key in r.keys():
                if key.startswith("tests"):
                    merged[imvp][key] = r[key]
        else:
            merged[imvp]["rfr"].update(r.get("rfr") or {})
            if not merged[imvp]["Section"] and (r.get("Section") or ""):
                merged[imvp]["Section"] = r["Section"]
            # Update test tag keys
            for key in r.keys():
                if key.startswith("tests"):
                    merged[imvp][key] = r[key]
    
    return list(merged.values())


def convert_csv(rows, document_path):
    file_name = os.path.basename(document_path)
    data = {"finding": rows}
    df = pd.DataFrame(data)
    df["file name"] = file_name
    df["type"] = "rfr"
    return df


def validate_rows(rows: List[Dict]) -> List[Dict]:
    for idx, r in enumerate(rows, start=1):
        imvp = (r.get("IMVP Question") or "").strip()
        rfr = r.get("rfr") or {}
        
        if not imvp or not imvp.endswith("?"):
            qkeys = list(rfr.keys())
            raise ValueError(
                f"Document is not formatted correctly: row {idx} missing IMVP question "
                f"(found rfr keys={qkeys}). Header must include a <...?> block."
            )
        
        if not isinstance(rfr, dict) or len(rfr) != 1:
            raise ValueError(
                f"Document is not formatted correctly: row {idx} has invalid rfr map: {rfr}"
            )
        
        (k, v) = next(iter(rfr.items()))
        if k.strip() in {"Q?", "Q3", "Q1", "Q2", "Q4", "Q5"} and k.strip() != imvp:
            raise ValueError(
                f"Document is not formatted correctly: row {idx} uses Q-ID '{k}' "
                f"instead of the RFR question.\n IMVP: {imvp}\n rfr key: {k}"
            )
        
        if not (v or "").strip():
            raise ValueError(
                f"Document is not formatted correctly: row {idx} has empty Modeling Team response for '{imvp}'"
            )
    
    return rows


# ---------- MAIN ----------

if __name__ == "__main__":
    DOCX_PATH = "FinalRFRorignal.docx"
    OUT_PATH = "rfr_rows.json"
    
    rows = parse_docx_to_rfr_rows(DOCX_PATH)
    rows = validate_rows(rows)
    rows = collapse_empty_imvp_into_previous(rows)
    rows = merge_rows_by_imvp(rows)
    
    df = convert_csv(rows, DOCX_PATH)
    print(df)
    
    with open(OUT_PATH, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")
    
    print(f"Wrote {len(rows)} row(s) to {OUT_PATH}")
