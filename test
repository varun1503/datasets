import concurrent.futures
import logging
from tqdm import tqdm
from safechain.icel import model  # Your custom model loader

logger = logging.getLogger(__name__)

class ConcurrentEmbedding:
    def __init__(self, model_idx: str, batch_size: int = 64):
        self.embedding_model = model(model_idx)
        self.batch_size = batch_size

    def _get_batch_embed(self, batch_start_idx, chunk_batch):
        try:
            texts = [chunk["content"] for chunk in chunk_batch]
            batch_embeddings = self.embedding_model.embed_documents(texts)
            return batch_start_idx, batch_embeddings
        except Exception as e:
            logger.error(f"Batch embedding failed at index {batch_start_idx}: {e}")
            return batch_start_idx, [None] * len(chunk_batch)

    def chunk_embedding(self, chunks_data):
        batches = [
            (i, chunks_data[i:i + self.batch_size])
            for i in range(0, len(chunks_data), self.batch_size)
        ]

        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            futures = [
                executor.submit(self._get_batch_embed, start_idx, chunk_batch)
                for start_idx, chunk_batch in batches
            ]

            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc="Batch embedding"):
                try:
                    start_idx, embeddings = future.result()
                    for i, emb in enumerate(embeddings):
                        if emb is not None:
                            chunks_data[start_idx + i]["embedding"] = emb
                        else:
                            logger.warning(f"No embedding for chunk {start_idx + i}")
                except Exception as e:
                    logger.error(f"Future processing failed: {e}")
                    raise

        return chunks_data
