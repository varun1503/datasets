import shap
import torch
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import kurtosis
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# Load pre-trained BERT model and tokenizer (modify as needed)
model_name = "bert-base-uncased"  # Change this if using another model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# Sample list of sentences with varying lengths
sentences = [
    "The weather is great today.",
    "I love traveling to new places.",
    "Machine learning is fascinating.",
    "This restaurant serves delicious food.",
    "The book was very interesting and informative.",
    "AI is the future of technology and innovation."
]

# Tokenize sentences
inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors="pt")

# Define SHAP explainer
explainer = shap.Explainer(model, tokenizer)

# Compute SHAP values
shap_values = explainer(sentences)

# Process SHAP values: Aggregate across tokens for each sentence
shap_sentence_values = [np.mean(np.abs(sv.values), axis=0) for sv in shap_values]

# Compute kurtosis for each sentence's SHAP values
kurtosis_values = [kurtosis(sv, fisher=True) for sv in shap_sentence_values]

# Plot kurtosis values
plt.figure(figsize=(10, 5))
plt.bar(range(len(sentences)), kurtosis_values, color="skyblue")
plt.xlabel("Sentence Index")
plt.ylabel("Kurtosis")
plt.title("Kurtosis of SHAP Values for Sentences")
plt.xticks(range(len(sentences)), range(1, len(sentences) + 1))
plt.show()

# Print kurtosis values
for i, k in enumerate(kurtosis_values):
    print(f"Sentence {i+1}: Kurtosis = {k:.4f}")
